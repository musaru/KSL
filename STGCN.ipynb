{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fc75871-441e-41af-b890-5a6f2b147156",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Our Dataset Image Classificaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bac2baaa-ff84-4794-9737-ce02345f508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reference from: https://github.com/yysijie/st-gcn/blob/master/net/utils/graph.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Graph:\n",
    "    \"\"\"The Graph to model the skeletons extracted by the Alpha-Pose.\n",
    "    Args:\n",
    "        - strategy: (string) must be one of the follow candidates\n",
    "            - uniform: Uniform Labeling,\n",
    "            - distance: Distance Partitioning,\n",
    "            - spatial: Spatial Configuration,\n",
    "        For more information, please refer to the section 'Partition Strategies'\n",
    "            in our paper (https://arxiv.org/abs/1801.07455).\n",
    "        - layout: (string) must be one of the follow candidates\n",
    "            - coco_cut: Is COCO format but cut 4 joints (L-R ears, L-R eyes) out.\n",
    "        - max_hop: (int) the maximal distance between two connected nodes.\n",
    "        - dilation: (int) controls the spacing between the kernel points.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 layout='coco_cut',\n",
    "                 strategy='uniform',\n",
    "                 max_hop=1,\n",
    "                 dilation=1):\n",
    "        self.max_hop = max_hop\n",
    "        self.dilation = dilation\n",
    "\n",
    "        self.get_edge(layout)\n",
    "        self.hop_dis = get_hop_distance(self.num_node, self.edge, max_hop)\n",
    "        self.get_adjacency(strategy)\n",
    "\n",
    "    def get_edge(self, layout):\n",
    "        if layout == 'coco_cut':\n",
    "            self.num_node = 14\n",
    "            self_link = [(i, i) for i in range(self.num_node)]\n",
    "            neighbor_link = [(6, 4), (4, 2), (2, 13), (13, 1), (5, 3), (3, 1), (12, 10),\n",
    "                             (10, 8), (8, 2), (11, 9), (9, 7), (7, 1), (13, 0)]\n",
    "            self.edge = self_link + neighbor_link\n",
    "            self.center = 13\n",
    "            \n",
    "        elif layout == 'mediapipe_KSL':\n",
    "            self.num_node = 47\n",
    "            self_link = [(i, i) for i in range(self.num_node)]\n",
    "            # used_key_points=\n",
    "            # [0,11,12,13,14]+[i for i in range(33,33+21)] + [i for i in range(54,54+21)] \n",
    "            neighbor_link = [(0,1),(0,2),(1,3),(2,4),(3,26),(4,5), # nose-arms-wrist\n",
    "                             \n",
    "                             (5,6),(6,7),(7,8),(8,9),\n",
    "                             (5,10),(10,11),(11,12),(12,13),\n",
    "                             (5,14),(14,15),(15,16),(16,17),\n",
    "                             (5,18),(18,19),(19,20),(20,21),\n",
    "                             (5,22),(22,23),(23,24),(24,25),\n",
    "                             \n",
    "                             (26,27),(27,28),(28,29),(29,30),\n",
    "                             (26,31),(31,32),(32,33),(33,34),\n",
    "                             (26,35),(35,36),(36,37),(37,38),\n",
    "                             (26,39),(39,40),(40,41),(41,42),\n",
    "                             (26,43),(43,44),(44,45),(45,46),\n",
    "                            ]\n",
    "            self.edge = self_link + neighbor_link\n",
    "            self.center = 0\n",
    "        else:\n",
    "            raise ValueError('This layout is not supported!')\n",
    "\n",
    "    def get_adjacency(self, strategy):\n",
    "        valid_hop = range(0, self.max_hop + 1, self.dilation)\n",
    "        adjacency = np.zeros((self.num_node, self.num_node))\n",
    "        for hop in valid_hop:\n",
    "            adjacency[self.hop_dis == hop] = 1\n",
    "        normalize_adjacency = normalize_digraph(adjacency)\n",
    "\n",
    "        if strategy == 'uniform':\n",
    "            A = np.zeros((1, self.num_node, self.num_node))\n",
    "            A[0] = normalize_adjacency\n",
    "            self.A = A\n",
    "        elif strategy == 'distance':\n",
    "            A = np.zeros((len(valid_hop), self.num_node, self.num_node))\n",
    "            for i, hop in enumerate(valid_hop):\n",
    "                A[i][self.hop_dis == hop] = normalize_adjacency[self.hop_dis ==\n",
    "                                                                hop]\n",
    "            self.A = A\n",
    "        elif strategy == 'spatial':\n",
    "            A = []\n",
    "            for hop in valid_hop:\n",
    "                a_root = np.zeros((self.num_node, self.num_node))\n",
    "                a_close = np.zeros((self.num_node, self.num_node))\n",
    "                a_further = np.zeros((self.num_node, self.num_node))\n",
    "                for i in range(self.num_node):\n",
    "                    for j in range(self.num_node):\n",
    "                        if self.hop_dis[j, i] == hop:\n",
    "                            if self.hop_dis[j, self.center] == self.hop_dis[i, self.center]:\n",
    "                                a_root[j, i] = normalize_adjacency[j, i]\n",
    "                            elif self.hop_dis[j, self.center] > self.hop_dis[i, self.center]:\n",
    "                                a_close[j, i] = normalize_adjacency[j, i]\n",
    "                            else:\n",
    "                                a_further[j, i] = normalize_adjacency[j, i]\n",
    "                if hop == 0:\n",
    "                    A.append(a_root)\n",
    "                else:\n",
    "                    A.append(a_root + a_close)\n",
    "                    A.append(a_further)\n",
    "            A = np.stack(A)\n",
    "            self.A = A\n",
    "            #self.A = np.swapaxes(np.swapaxes(A, 0, 1), 1, 2)\n",
    "        else:\n",
    "            raise ValueError(\"This strategy is not supported!\")\n",
    "\n",
    "\n",
    "def get_hop_distance(num_node, edge, max_hop=1):\n",
    "    A = np.zeros((num_node, num_node))\n",
    "    for i, j in edge:\n",
    "        A[j, i] = 1\n",
    "        A[i, j] = 1\n",
    "\n",
    "    # compute hop steps\n",
    "    hop_dis = np.zeros((num_node, num_node)) + np.inf\n",
    "    transfer_mat = [np.linalg.matrix_power(A, d) for d in range(max_hop + 1)]\n",
    "    arrive_mat = (np.stack(transfer_mat) > 0)\n",
    "    for d in range(max_hop, -1, -1):\n",
    "        hop_dis[arrive_mat[d]] = d\n",
    "    return hop_dis\n",
    "\n",
    "\n",
    "def normalize_digraph(A):\n",
    "    Dl = np.sum(A, 0)\n",
    "    num_node = A.shape[0]\n",
    "    Dn = np.zeros((num_node, num_node))\n",
    "    for i in range(num_node):\n",
    "        if Dl[i] > 0:\n",
    "            Dn[i, i] = Dl[i]**(-1)\n",
    "    AD = np.dot(A, Dn)\n",
    "    return AD\n",
    "\n",
    "\n",
    "def normalize_undigraph(A):\n",
    "    Dl = np.sum(A, 0)\n",
    "    num_node = A.shape[0]\n",
    "    Dn = np.zeros((num_node, num_node))\n",
    "    for i in range(num_node):\n",
    "        if Dl[i] > 0:\n",
    "            Dn[i, i] = Dl[i]**(-0.5)\n",
    "    DAD = np.dot(np.dot(Dn, A), Dn)\n",
    "    return DAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff3e0972-c5d3-40f7-888c-cd345e27a358",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reference from: https://github.com/yysijie/st-gcn/tree/master/net\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# from Actionsrecognition.Utils import Graph\n",
    "\n",
    "\n",
    "class GraphConvolution(nn.Module):\n",
    "    \"\"\"The basic module for applying a graph convolution.\n",
    "    Args:\n",
    "        - in_channel: (int) Number of channels in the input sequence data.\n",
    "        - out_channels: (int) Number of channels produced by the convolution.\n",
    "        - kernel_size: (int) Size of the graph convolving kernel.\n",
    "        - t_kernel_size: (int) Size of the temporal convolving kernel.\n",
    "        - t_stride: (int, optional) Stride of the temporal convolution. Default: 1\n",
    "        - t_padding: (int, optional) Temporal zero-padding added to both sides of\n",
    "            the input. Default: 0\n",
    "        - t_dilation: (int, optional) Spacing between temporal kernel elements. Default: 1\n",
    "        - bias: (bool, optional) If `True`, adds a learnable bias to the output.\n",
    "            Default: `True`\n",
    "    Shape:\n",
    "        - Inputs x: Graph sequence in :math:`(N, in_channels, T_{in}, V)`,\n",
    "                 A: Graph adjacency matrix in :math:`(K, V, V)`,\n",
    "        - Output: Graph sequence out in :math:`(N, out_channels, T_{out}, V)`\n",
    "\n",
    "            where\n",
    "                :math:`N` is a batch size,\n",
    "                :math:`K` is the spatial kernel size, as :math:`K == kernel_size[1]`,\n",
    "                :math:`T_{in}/T_{out}` is a length of input/output sequence,\n",
    "                :math:`V` is the number of graph nodes.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 t_kernel_size=1,\n",
    "                 t_stride=1,\n",
    "                 t_padding=0,\n",
    "                 t_dilation=1,\n",
    "                 bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv = nn.Conv2d(in_channels,\n",
    "                              out_channels * kernel_size,\n",
    "                              kernel_size=(t_kernel_size, 1),\n",
    "                              padding=(t_padding, 0),\n",
    "                              stride=(t_stride, 1),\n",
    "                              dilation=(t_dilation, 1),\n",
    "                              bias=bias)\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        x = self.conv(x)\n",
    "        n, kc, t, v = x.size()\n",
    "        x = x.view(n, self.kernel_size, kc//self.kernel_size, t, v)\n",
    "        x = torch.einsum('nkctv,kvw->nctw', (x, A))\n",
    "\n",
    "        return x.contiguous()\n",
    "\n",
    "\n",
    "class st_gcn(nn.Module):\n",
    "    \"\"\"Applies a spatial temporal graph convolution over an input graph sequence.\n",
    "    Args:\n",
    "        - in_channels: (int) Number of channels in the input sequence data.\n",
    "        - out_channels: (int) Number of channels produced by the convolution.\n",
    "        - kernel_size: (tuple) Size of the temporal convolving kernel and\n",
    "            graph convolving kernel.\n",
    "        - stride: (int, optional) Stride of the temporal convolution. Default: 1\n",
    "        - dropout: (int, optional) Dropout rate of the final output. Default: 0\n",
    "        - residual: (bool, optional) If `True`, applies a residual mechanism.\n",
    "            Default: `True`\n",
    "    Shape:\n",
    "        - Inputs x: Graph sequence in :math: `(N, in_channels, T_{in}, V)`,\n",
    "                 A: Graph Adjecency matrix in :math: `(K, V, V)`,\n",
    "        - Output: Graph sequence out in :math: `(N, out_channels, T_{out}, V)`\n",
    "            where\n",
    "                :math:`N` is a batch size,\n",
    "                :math:`K` is the spatial kernel size, as :math:`K == kernel_size[1]`,\n",
    "                :math:`T_{in}/T_{out}` is a length of input/output sequence,\n",
    "                :math:`V` is the number of graph nodes.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 stride=1,\n",
    "                 dropout=0,\n",
    "                 residual=True):\n",
    "        super().__init__()\n",
    "        assert len(kernel_size) == 2\n",
    "        assert kernel_size[0] % 2 == 1\n",
    "        #print(kernel_size)(9, 3)\n",
    "        padding = ((kernel_size[0] - 1) // 2, 0)\n",
    "        #print(padding)(4, 0)\n",
    "\n",
    "        self.gcn = GraphConvolution(in_channels, out_channels, kernel_size[1])\n",
    "        self.tcn = nn.Sequential(nn.BatchNorm2d(out_channels),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                                 nn.Conv2d(out_channels,\n",
    "                                           out_channels,\n",
    "                                           (kernel_size[0], 1),\n",
    "                                           (stride, 1),\n",
    "                                           padding),\n",
    "                                 nn.BatchNorm2d(out_channels),\n",
    "                                 nn.Dropout(dropout, inplace=True),\n",
    "                                 )\n",
    "\n",
    "        if not residual:\n",
    "            self.residual = lambda x: 0\n",
    "        elif (in_channels == out_channels) and (stride == 1):\n",
    "            self.residual = lambda x: x\n",
    "        else:\n",
    "            self.residual = nn.Sequential(nn.Conv2d(in_channels,\n",
    "                                                    out_channels,\n",
    "                                                    kernel_size=1,\n",
    "                                                    stride=(stride, 1)),\n",
    "                                          nn.BatchNorm2d(out_channels)\n",
    "                                          )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        res = self.residual(x)\n",
    "        # print(res)\n",
    "        x = self.gcn(x, A)\n",
    "        #print(\"x_in:\",x.size())\n",
    "        x = self.tcn(x) + res\n",
    "        #print(\"x_out:\",x.size())\n",
    "        return self.relu(x)\n",
    "\n",
    "\n",
    "class StreamSpatialTemporalGraph(nn.Module):\n",
    "    \"\"\"Spatial temporal graph convolutional networks.\n",
    "    Args:\n",
    "        - in_channels: (int) Number of input channels.\n",
    "        - graph_args: (dict) Args map of `Actionsrecognition.Utils.Graph` Class.\n",
    "        - num_class: (int) Number of class outputs. If `None` return pooling features of\n",
    "            the last st-gcn layer instead.\n",
    "        - edge_importance_weighting: (bool) If `True`, adds a learnable importance\n",
    "            weighting to the edges of the graph.\n",
    "        - **kwargs: (optional) Other parameters for graph convolution units.\n",
    "    Shape:\n",
    "        - Input: :math:`(N, in_channels, T_{in}, V_{in})`\n",
    "        - Output: :math:`(N, num_class)` where\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`T_{in}` is a length of input sequence,\n",
    "            :math:`V_{in}` is the number of graph nodes,\n",
    "        or If num_class is `None`: `(N, out_channels)`\n",
    "            :math:`out_channels` is number of out_channels of the last layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, graph_args, num_class=None,\n",
    "                 edge_importance_weighting=True, **kwargs):\n",
    "        super().__init__()\n",
    "        # Load graph.\n",
    "        graph = Graph(**graph_args)\n",
    "        A = torch.tensor(graph.A, dtype=torch.float32, requires_grad=False)\n",
    "        self.register_buffer('A', A)\n",
    "\n",
    "        # Networks.\n",
    "        spatial_kernel_size = A.size(0)\n",
    "        temporal_kernel_size = 9\n",
    "        kernel_size = (temporal_kernel_size, spatial_kernel_size)\n",
    "        kwargs0 = {k: v for k, v in kwargs.items() if k != 'dropout'}\n",
    "\n",
    "        self.data_bn = nn.BatchNorm1d(in_channels * A.size(1))\n",
    "        self.st_gcn_networks = nn.ModuleList((\n",
    "            st_gcn(in_channels, 64, kernel_size, 1, residual=False, **kwargs0),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 128, kernel_size, 2, **kwargs),\n",
    "            st_gcn(128, 128, kernel_size, 1, **kwargs),\n",
    "            st_gcn(128, 128, kernel_size, 1, **kwargs),\n",
    "            st_gcn(128, 256, kernel_size, 2, **kwargs),\n",
    "            st_gcn(256, 256, kernel_size, 1, **kwargs),\n",
    "            st_gcn(256, 256, kernel_size, 1, **kwargs)\n",
    "        ))\n",
    "\n",
    "        # initialize parameters for edge importance weighting.\n",
    "        if edge_importance_weighting:\n",
    "            self.edge_importance = nn.ParameterList([\n",
    "                nn.Parameter(torch.ones(A.size()))\n",
    "                for i in self.st_gcn_networks\n",
    "            ])\n",
    "        else:\n",
    "            self.edge_importance = [1] * len(self.st_gcn_networks)\n",
    "\n",
    "        if num_class is not None:\n",
    "            self.cls = nn.Conv2d(256, num_class, kernel_size=1)\n",
    "        else:\n",
    "            self.cls = lambda x: x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # data normalization.\n",
    "        N, C, T, V = x.size()\n",
    "        x = x.permute(0, 3, 1, 2).contiguous()  # (N, V, C, T)\n",
    "        x = x.view(N, V * C, T)\n",
    "        x = self.data_bn(x)\n",
    "        x = x.view(N, V, C, T)\n",
    "        x = x.permute(0, 2, 3, 1).contiguous()\n",
    "        x = x.view(N, C, T, V)\n",
    "\n",
    "        # forward.\n",
    "        for gcn, importance in zip(self.st_gcn_networks, self.edge_importance):\n",
    "            x = gcn(x, self.A * importance)\n",
    "\n",
    "        x = F.avg_pool2d(x, x.size()[2:])\n",
    "        x = self.cls(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class TwoStreamSpatialTemporalGraph(nn.Module):\n",
    "    \"\"\"Two inputs spatial temporal graph convolutional networks.\n",
    "    Args:\n",
    "        - graph_args: (dict) Args map of `Actionsrecognition.Utils.Graph` Class.\n",
    "        - num_class: (int) Number of class outputs.\n",
    "        - edge_importance_weighting: (bool) If `True`, adds a learnable importance\n",
    "            weighting to the edges of the graph.\n",
    "        - **kwargs: (optional) Other parameters for graph convolution units.\n",
    "    Shape:\n",
    "        - Input: :tuple of math:`((N, 3, T, V), (N, 2, T, V))`\n",
    "        for points and motions stream where.\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`in_channels` is data channels (3 is (x, y, score)), (2 is (mot_x, mot_y))\n",
    "            :math:`T` is a length of input sequence,\n",
    "            :math:`V` is the number of graph nodes,\n",
    "        - Output: :math:`(N, num_class)`\n",
    "    \"\"\"\n",
    "    def __init__(self, graph_args, num_class, edge_importance_weighting=True,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.pts_stream = StreamSpatialTemporalGraph(3, graph_args, None,\n",
    "                                                     edge_importance_weighting,\n",
    "                                                     **kwargs)\n",
    "        self.mot_stream = StreamSpatialTemporalGraph(3, graph_args, None,\n",
    "                                                     edge_importance_weighting,\n",
    "                                                     **kwargs)\n",
    "\n",
    "        # self.fcn = nn.Linear(256 * 2, num_class)\n",
    "        self.fcn = nn.Linear(256 , num_class)\n",
    "        \n",
    "        # self.atten1 = nn.Linear(256 * 2, 128)\n",
    "        # self.atten_bn = nn.BatchNorm1d(128)\n",
    "        # self.atten_relu= nn.ReLU(inplace=True)\n",
    "        # self.atten2 = nn.Linear(128,32)\n",
    "        # self.atten_relu2= nn.ReLU(inplace=True)\n",
    "        # self.atten3 = nn.Linear(32, 256 * 2)\n",
    "        # self.atten_act = nn.Sigmoid() \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        out1 = self.pts_stream(inputs[0])\n",
    "        # out2 = self.mot_stream(inputs[1])\n",
    "        \n",
    "        #print(out1.size())torch.Size([32, 256])\n",
    "        #print(out2.size())torch.Size([32, 256])\n",
    "        # concat = torch.cat([out1, out2], dim=-1)\n",
    "        \n",
    "        # attn = self.atten1(concat)\n",
    "        # attn = self.atten_bn(attn)\n",
    "        # attn = self.atten_relu(attn)\n",
    "        # attn = self.atten2(attn)\n",
    "        # attn = self.atten_relu2(attn)\n",
    "        # attn = self.atten3(attn)\n",
    "        # attn = self.atten_act(attn)\n",
    "        # concat = concat * attn\n",
    "        \n",
    "        \n",
    "        # out = self.fcn(concat)\n",
    "        out = self.fcn(out1)\n",
    "        \n",
    "        return out\n",
    "        # return torch.sigmoid(out)\n",
    "        #return F.softmax(out,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bc339b5-4a5a-4f6d-bb88-7aa6039c3d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n"
     ]
    }
   ],
   "source": [
    "num_class=20\n",
    "\n",
    "graph_args = {'layout':'mediapipe_KSL','strategy': 'spatial'}\n",
    "model = TwoStreamSpatialTemporalGraph(graph_args, num_class)\n",
    "a=torch.randn(1,3,40,47)\n",
    "b=torch.randn(1,3,40,47)\n",
    "# print(model)\n",
    "out = model((a,b))\n",
    "print(out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1610b498-1dd3-4fda-8a23-3d92d83ff4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device\n",
      "(129459, 3, 1, 47)\n",
      "(129459,)\n",
      "number of params: 6267268\n",
      "Epoch 0/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.28it/s,  loss: 0.1763, accu: 0.9333]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 220.73it/s,  loss: 1.0722, accu: 0.7500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.6597, accu: 0.7754\n",
      " - Valid loss: 0.3473, accu: 0.8924\n",
      "Epoch 1/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.47it/s,  loss: 0.0760, accu: 1.0000]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 220.69it/s,  loss: 0.7393, accu: 0.7500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.1868, accu: 0.9371\n",
      " - Valid loss: 0.2266, accu: 0.9503\n",
      "Epoch 2/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.35it/s,  loss: 0.0786, accu: 1.0000]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 221.04it/s,  loss: 0.3984, accu: 0.7500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.1170, accu: 0.9616\n",
      " - Valid loss: 0.0795, accu: 0.9790\n",
      "Epoch 3/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.44it/s,  loss: 0.2121, accu: 0.9333]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 220.46it/s,  loss: 1.4689, accu: 0.7500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0883, accu: 0.9709\n",
      " - Valid loss: 0.1798, accu: 0.9430\n",
      "Epoch 4/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.33it/s,  loss: 0.0366, accu: 1.0000]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 220.39it/s,  loss: 0.0181, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0714, accu: 0.9761\n",
      " - Valid loss: 0.0959, accu: 0.9742\n",
      "Epoch 5/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.39it/s,  loss: 0.0004, accu: 1.0000]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 220.33it/s,  loss: 0.0476, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0609, accu: 0.9801\n",
      " - Valid loss: 0.0487, accu: 0.9917\n",
      "Epoch 6/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.17it/s,  loss: 0.0088, accu: 1.0000]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 221.46it/s,  loss: 0.0026, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0537, accu: 0.9827\n",
      " - Valid loss: 0.0551, accu: 0.9868\n",
      "Epoch 7/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.15it/s,  loss: 0.0057, accu: 1.0000]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 221.67it/s,  loss: 0.4199, accu: 0.7500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0464, accu: 0.9844\n",
      " - Valid loss: 0.0442, accu: 0.9880\n",
      "Epoch 8/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.26it/s,  loss: 0.0004, accu: 1.0000]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 220.27it/s,  loss: 0.0017, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0440, accu: 0.9852\n",
      " - Valid loss: 0.0372, accu: 0.9924\n",
      "Epoch 9/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.35it/s,  loss: 0.0001, accu: 1.0000]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 219.45it/s,  loss: 0.7450, accu: 0.7500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0403, accu: 0.9868\n",
      " - Valid loss: 0.0530, accu: 0.9823\n",
      "Epoch 10/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.54it/s,  loss: 0.3293, accu: 0.9333]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 221.07it/s,  loss: 2.6464, accu: 0.7500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0366, accu: 0.9880\n",
      " - Valid loss: 0.3617, accu: 0.9279\n",
      "Epoch 11/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.34it/s,  loss: 0.1618, accu: 0.9333]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 220.62it/s,  loss: 1.2822, accu: 0.7500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0348, accu: 0.9886\n",
      " - Valid loss: 0.0848, accu: 0.9752\n",
      "Epoch 12/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.24it/s,  loss: 0.0008, accu: 1.0000]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 220.98it/s,  loss: 0.0083, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0314, accu: 0.9899\n",
      " - Valid loss: 0.0265, accu: 0.9929\n",
      "Epoch 13/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.39it/s,  loss: 0.0618, accu: 1.0000]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 220.96it/s,  loss: 0.0000, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0302, accu: 0.9898\n",
      " - Valid loss: 0.0177, accu: 0.9953\n",
      "Epoch 14/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.52it/s,  loss: 0.0213, accu: 1.0000]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 219.97it/s,  loss: 0.0138, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0288, accu: 0.9906\n",
      " - Valid loss: 0.0373, accu: 0.9897\n",
      "Epoch 15/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.41it/s,  loss: 0.0321, accu: 1.0000]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 220.18it/s,  loss: 0.4398, accu: 0.7500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0268, accu: 0.9909\n",
      " - Valid loss: 0.0433, accu: 0.9867\n",
      "Epoch 16/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.44it/s,  loss: 0.3201, accu: 0.9333]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 220.32it/s,  loss: 0.0033, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0258, accu: 0.9916\n",
      " - Valid loss: 0.0287, accu: 0.9908\n",
      "Epoch 17/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.29it/s,  loss: 0.1812, accu: 0.9333]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 221.26it/s,  loss: 0.0107, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0253, accu: 0.9916\n",
      " - Valid loss: 0.1005, accu: 0.9701\n",
      "Epoch 18/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.40it/s,  loss: 0.0151, accu: 1.0000]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 220.96it/s,  loss: 0.0005, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0240, accu: 0.9920\n",
      " - Valid loss: 0.0261, accu: 0.9959\n",
      "Epoch 19/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.29it/s,  loss: 0.0312, accu: 1.0000]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 220.11it/s,  loss: 0.0174, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0234, accu: 0.9922\n",
      " - Valid loss: 0.0366, accu: 0.9877\n",
      "Epoch 20/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.25it/s,  loss: 0.0126, accu: 1.0000]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 220.35it/s,  loss: 0.0068, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0221, accu: 0.9923\n",
      " - Valid loss: 0.0245, accu: 0.9952\n",
      "Epoch 21/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.42it/s,  loss: 0.0060, accu: 1.0000]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 220.36it/s,  loss: 0.0090, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0224, accu: 0.9926\n",
      " - Valid loss: 0.0391, accu: 0.9864\n",
      "Epoch 22/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.34it/s,  loss: 0.0319, accu: 1.0000]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 220.98it/s,  loss: 0.0142, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0207, accu: 0.9933\n",
      " - Valid loss: 0.0257, accu: 0.9931\n",
      "Epoch 23/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.34it/s,  loss: 0.0157, accu: 1.0000]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 220.52it/s,  loss: 0.0006, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0208, accu: 0.9930\n",
      " - Valid loss: 0.0239, accu: 0.9961\n",
      "Epoch 24/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.48it/s,  loss: 0.0102, accu: 1.0000]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 221.27it/s,  loss: 0.3277, accu: 0.7500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0209, accu: 0.9932\n",
      " - Valid loss: 0.0263, accu: 0.9930\n",
      "Epoch 25/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.35it/s,  loss: 0.0007, accu: 1.0000]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 221.38it/s,  loss: 0.0426, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0186, accu: 0.9937\n",
      " - Valid loss: 0.0290, accu: 0.9922\n",
      "Epoch 26/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.52it/s,  loss: 0.0008, accu: 1.0000]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 220.85it/s,  loss: 0.0000, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0191, accu: 0.9939\n",
      " - Valid loss: 0.0474, accu: 0.9884\n",
      "Epoch 27/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.48it/s,  loss: 0.0001, accu: 1.0000]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 220.11it/s,  loss: 0.0001, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0185, accu: 0.9939\n",
      " - Valid loss: 0.0279, accu: 0.9925\n",
      "Epoch 28/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.51it/s,  loss: 0.0003, accu: 1.0000]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 221.13it/s,  loss: 0.0199, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0188, accu: 0.9940\n",
      " - Valid loss: 0.0283, accu: 0.9931\n",
      "Epoch 29/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 3237/3237 [00:46<00:00, 69.53it/s,  loss: 0.1341, accu: 0.9333]\n",
      "valid: 100%|██████████| 810/810 [00:03<00:00, 220.09it/s,  loss: 0.0095, accu: 1.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0180, accu: 0.9942\n",
      " - Valid loss: 0.0248, accu: 0.9927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from shutil import copyfile\n",
    "from tqdm import tqdm\n",
    "from torch.utils import data\n",
    "from torch.optim.adadelta import Adadelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#device = 'cuda'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"using\", device, \"device\")\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 32 #32\n",
    "\n",
    "def load_dataset(data_files, batch_size, split_size=0.2,used_key_points=None):#0.2\n",
    "    \"\"\"Load data files into torch DataLoader with/without spliting train-test.\n",
    "    \"\"\"\n",
    "    features, labels = [], []\n",
    "    for fil in data_files:\n",
    "        with open(fil, 'rb') as f:\n",
    "            fts, lbs = pickle.load(f)\n",
    "            features.append(fts)\n",
    "            labels.append(lbs)\n",
    "        del fts, lbs\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    \n",
    "    if used_key_points != None:\n",
    "        features = features[:,:,:,used_key_points]\n",
    "    print(features.shape)\n",
    "    print(labels.shape)\n",
    "\n",
    "    if split_size > 0:\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(features, labels, test_size=split_size,random_state=0,stratify=labels)\n",
    "        \n",
    "        train_set = data.TensorDataset(torch.tensor(x_train, dtype=torch.float32),torch.tensor(y_train, dtype=torch.int64))\n",
    "        valid_set = data.TensorDataset(torch.tensor(x_valid, dtype=torch.float32),torch.tensor(y_valid, dtype=torch.int64))\n",
    "        train_loader = data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "        valid_loader = data.DataLoader(valid_set, batch_size)\n",
    "    else:\n",
    "        train_set = data.TensorDataset(torch.tensor(features, dtype=torch.float32),torch.tensor(labels, dtype=torch.int64))\n",
    "        train_loader = data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "        valid_loader = None\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "def accuracy_batch(y_pred, y_true):\n",
    "    # print(y_pred.shape,y_true.shape)\n",
    "    # return (y_pred.argmax(1) == y_true.argmax(1)).mean()\n",
    "    return (y_pred.argmax(1) == y_true).mean()\n",
    "\n",
    "\n",
    "def set_training(model, mode=True):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = mode\n",
    "    model.train(mode)\n",
    "    return model\n",
    "\n",
    "save_folder = os.path.join(os.environ['HOME'],\"KSL_V2/Outputs\")\n",
    "os.makedirs(save_folder,exist_ok=True)\n",
    "used_key_points=[0,11,12,13,14]+[i for i in range(33,33+21)] + [i for i in range(54,54+21)] \n",
    "train_loader, valid_loader = load_dataset([os.path.join(os.environ['HOME'],\"KSL_V2/Datasets/KSL_1_dataset.pkl\")], 32,0.2,used_key_points) #batch_size = 32\n",
    "dataloader = {'train': train_loader, 'valid': valid_loader}\n",
    "num_class=20\n",
    "\n",
    "graph_args = {'layout':'mediapipe_KSL','strategy': 'spatial'}\n",
    "model = TwoStreamSpatialTemporalGraph(graph_args, num_class).to(device)\n",
    "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"number of params: {n_parameters}\")\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "losser = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "loss_list = {'train': [], 'valid': []}\n",
    "accu_list = {'train': [], 'valid': []}\n",
    "best_acc = -1\n",
    "for e in range(epochs):\n",
    "    print('Epoch {}/{}'.format(e, epochs - 1))\n",
    "    for phase in ['train', 'valid']:\n",
    "        if phase == 'train':\n",
    "            model = set_training(model, True)\n",
    "        else:\n",
    "            model = set_training(model, False)\n",
    "\n",
    "        run_loss = 0.0\n",
    "        run_accu = 0.0\n",
    "        with tqdm(dataloader[phase], desc=phase) as iterator:\n",
    "            for pts, lbs in iterator:\n",
    "                # Create motion input by distance of points (x, y) of the same node\n",
    "                # in two frames.\n",
    "                mot = pts[:, :, 1:, :] - pts[:, :, :-1, :]\n",
    "\n",
    "                mot = mot.to(device)\n",
    "                pts = pts.to(device)\n",
    "                lbs = lbs.to(device)\n",
    "                \n",
    "                # Forward.\n",
    "                out = model((pts, mot))\n",
    "                #print(lbs)\n",
    "\n",
    "                #print(out)\n",
    "                loss = losser(out, lbs)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    # Backward.\n",
    "                    model.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                run_loss += loss.item()\n",
    "                accu = accuracy_batch(out.detach().cpu().numpy(),\n",
    "                                      lbs.detach().cpu().numpy())\n",
    "                run_accu += accu\n",
    "\n",
    "                iterator.set_postfix_str(' loss: {:.4f}, accu: {:.4f}'.format(\n",
    "                    loss.item(), accu))\n",
    "                iterator.update()\n",
    "                #break\n",
    "        loss_list[phase].append(run_loss / len(iterator))\n",
    "        accu_list[phase].append(run_accu / len(iterator))\n",
    "        #print(accu_list)\n",
    "        #print(torch.max(accu_list))\n",
    "    if(best_acc < accu_list['valid'][-1]):\n",
    "        best_acc = accu_list['valid'][-1]\n",
    "        torch.save(model.state_dict(), os.path.join(save_folder, 'tsstg-model_best.pth'))\n",
    "        #break\n",
    "\n",
    "    print('Summary epoch:\\n - Train loss: {:.4f}, accu: {:.4f}\\n - Valid loss:'\n",
    "          ' {:.4f}, accu: {:.4f}'.format(loss_list['train'][-1], accu_list['train'][-1],\n",
    "                                         loss_list['valid'][-1], accu_list['valid'][-1]))\n",
    "del model\n",
    "# 0.9655696902654868"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8602c3-01c1-4f64-ad31-e0818865837f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493c0ed8-6833-4a38-8540-fe7dbadc4da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d73344-6e4e-4be8-83de-9398d6dd6f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2df669-1549-4305-8b10-e43577540655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fecb753-52c5-46ff-a04a-e52d5231517d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33342873-7abd-461b-ba71-14cda87d9b10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb24d8d8-b32d-415e-8708-030d4d4a8aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2540aeb4-38ae-43d5-9221-1ebfac474aec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a53a7a8-f090-40ec-88c5-b905dd6b8f8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Our Dataset Video Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa5dc492-c033-4d57-8641-5e3a6bdb926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reference from: https://github.com/yysijie/st-gcn/blob/master/net/utils/graph.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Graph:\n",
    "    \"\"\"The Graph to model the skeletons extracted by the Alpha-Pose.\n",
    "    Args:\n",
    "        - strategy: (string) must be one of the follow candidates\n",
    "            - uniform: Uniform Labeling,\n",
    "            - distance: Distance Partitioning,\n",
    "            - spatial: Spatial Configuration,\n",
    "        For more information, please refer to the section 'Partition Strategies'\n",
    "            in our paper (https://arxiv.org/abs/1801.07455).\n",
    "        - layout: (string) must be one of the follow candidates\n",
    "            - coco_cut: Is COCO format but cut 4 joints (L-R ears, L-R eyes) out.\n",
    "        - max_hop: (int) the maximal distance between two connected nodes.\n",
    "        - dilation: (int) controls the spacing between the kernel points.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 layout='coco_cut',\n",
    "                 strategy='uniform',\n",
    "                 max_hop=1,\n",
    "                 dilation=1):\n",
    "        self.max_hop = max_hop\n",
    "        self.dilation = dilation\n",
    "\n",
    "        self.get_edge(layout)\n",
    "        self.hop_dis = get_hop_distance(self.num_node, self.edge, max_hop)\n",
    "        self.get_adjacency(strategy)\n",
    "\n",
    "    def get_edge(self, layout):\n",
    "        if layout == 'coco_cut':\n",
    "            self.num_node = 14\n",
    "            self_link = [(i, i) for i in range(self.num_node)]\n",
    "            neighbor_link = [(6, 4), (4, 2), (2, 13), (13, 1), (5, 3), (3, 1), (12, 10),\n",
    "                             (10, 8), (8, 2), (11, 9), (9, 7), (7, 1), (13, 0)]\n",
    "            self.edge = self_link + neighbor_link\n",
    "            self.center = 13\n",
    "            \n",
    "        elif layout == 'mediapipe_KSL':\n",
    "            self.num_node = 47\n",
    "            self_link = [(i, i) for i in range(self.num_node)]\n",
    "            # used_key_points=\n",
    "            # [0,11,12,13,14]+[i for i in range(33,33+21)] + [i for i in range(54,54+21)] \n",
    "            neighbor_link = [(0,1),(0,2),(1,3),(2,4),(3,26),(4,5), # nose-arms-wrist\n",
    "                             \n",
    "                             (5,6),(6,7),(7,8),(8,9),\n",
    "                             (5,10),(10,11),(11,12),(12,13),\n",
    "                             (5,14),(14,15),(15,16),(16,17),\n",
    "                             (5,18),(18,19),(19,20),(20,21),\n",
    "                             (5,22),(22,23),(23,24),(24,25),\n",
    "                             \n",
    "                             (26,27),(27,28),(28,29),(29,30),\n",
    "                             (26,31),(31,32),(32,33),(33,34),\n",
    "                             (26,35),(35,36),(36,37),(37,38),\n",
    "                             (26,39),(39,40),(40,41),(41,42),\n",
    "                             (26,43),(43,44),(44,45),(45,46),\n",
    "                            ]\n",
    "            self.edge = self_link + neighbor_link\n",
    "            self.center = 0\n",
    "        else:\n",
    "            raise ValueError('This layout is not supported!')\n",
    "\n",
    "    def get_adjacency(self, strategy):\n",
    "        valid_hop = range(0, self.max_hop + 1, self.dilation)\n",
    "        adjacency = np.zeros((self.num_node, self.num_node))\n",
    "        for hop in valid_hop:\n",
    "            adjacency[self.hop_dis == hop] = 1\n",
    "        normalize_adjacency = normalize_digraph(adjacency)\n",
    "\n",
    "        if strategy == 'uniform':\n",
    "            A = np.zeros((1, self.num_node, self.num_node))\n",
    "            A[0] = normalize_adjacency\n",
    "            self.A = A\n",
    "        elif strategy == 'distance':\n",
    "            A = np.zeros((len(valid_hop), self.num_node, self.num_node))\n",
    "            for i, hop in enumerate(valid_hop):\n",
    "                A[i][self.hop_dis == hop] = normalize_adjacency[self.hop_dis ==\n",
    "                                                                hop]\n",
    "            self.A = A\n",
    "        elif strategy == 'spatial':\n",
    "            A = []\n",
    "            for hop in valid_hop:\n",
    "                a_root = np.zeros((self.num_node, self.num_node))\n",
    "                a_close = np.zeros((self.num_node, self.num_node))\n",
    "                a_further = np.zeros((self.num_node, self.num_node))\n",
    "                for i in range(self.num_node):\n",
    "                    for j in range(self.num_node):\n",
    "                        if self.hop_dis[j, i] == hop:\n",
    "                            if self.hop_dis[j, self.center] == self.hop_dis[i, self.center]:\n",
    "                                a_root[j, i] = normalize_adjacency[j, i]\n",
    "                            elif self.hop_dis[j, self.center] > self.hop_dis[i, self.center]:\n",
    "                                a_close[j, i] = normalize_adjacency[j, i]\n",
    "                            else:\n",
    "                                a_further[j, i] = normalize_adjacency[j, i]\n",
    "                if hop == 0:\n",
    "                    A.append(a_root)\n",
    "                else:\n",
    "                    A.append(a_root + a_close)\n",
    "                    A.append(a_further)\n",
    "            A = np.stack(A)\n",
    "            self.A = A\n",
    "            #self.A = np.swapaxes(np.swapaxes(A, 0, 1), 1, 2)\n",
    "        else:\n",
    "            raise ValueError(\"This strategy is not supported!\")\n",
    "\n",
    "\n",
    "def get_hop_distance(num_node, edge, max_hop=1):\n",
    "    A = np.zeros((num_node, num_node))\n",
    "    for i, j in edge:\n",
    "        A[j, i] = 1\n",
    "        A[i, j] = 1\n",
    "\n",
    "    # compute hop steps\n",
    "    hop_dis = np.zeros((num_node, num_node)) + np.inf\n",
    "    transfer_mat = [np.linalg.matrix_power(A, d) for d in range(max_hop + 1)]\n",
    "    arrive_mat = (np.stack(transfer_mat) > 0)\n",
    "    for d in range(max_hop, -1, -1):\n",
    "        hop_dis[arrive_mat[d]] = d\n",
    "    return hop_dis\n",
    "\n",
    "\n",
    "def normalize_digraph(A):\n",
    "    Dl = np.sum(A, 0)\n",
    "    num_node = A.shape[0]\n",
    "    Dn = np.zeros((num_node, num_node))\n",
    "    for i in range(num_node):\n",
    "        if Dl[i] > 0:\n",
    "            Dn[i, i] = Dl[i]**(-1)\n",
    "    AD = np.dot(A, Dn)\n",
    "    return AD\n",
    "\n",
    "\n",
    "def normalize_undigraph(A):\n",
    "    Dl = np.sum(A, 0)\n",
    "    num_node = A.shape[0]\n",
    "    Dn = np.zeros((num_node, num_node))\n",
    "    for i in range(num_node):\n",
    "        if Dl[i] > 0:\n",
    "            Dn[i, i] = Dl[i]**(-0.5)\n",
    "    DAD = np.dot(np.dot(Dn, A), Dn)\n",
    "    return DAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28266018-c233-40e1-9b0b-7c2c06e4b098",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reference from: https://github.com/yysijie/st-gcn/tree/master/net\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# from Actionsrecognition.Utils import Graph\n",
    "\n",
    "\n",
    "class GraphConvolution(nn.Module):\n",
    "    \"\"\"The basic module for applying a graph convolution.\n",
    "    Args:\n",
    "        - in_channel: (int) Number of channels in the input sequence data.\n",
    "        - out_channels: (int) Number of channels produced by the convolution.\n",
    "        - kernel_size: (int) Size of the graph convolving kernel.\n",
    "        - t_kernel_size: (int) Size of the temporal convolving kernel.\n",
    "        - t_stride: (int, optional) Stride of the temporal convolution. Default: 1\n",
    "        - t_padding: (int, optional) Temporal zero-padding added to both sides of\n",
    "            the input. Default: 0\n",
    "        - t_dilation: (int, optional) Spacing between temporal kernel elements. Default: 1\n",
    "        - bias: (bool, optional) If `True`, adds a learnable bias to the output.\n",
    "            Default: `True`\n",
    "    Shape:\n",
    "        - Inputs x: Graph sequence in :math:`(N, in_channels, T_{in}, V)`,\n",
    "                 A: Graph adjacency matrix in :math:`(K, V, V)`,\n",
    "        - Output: Graph sequence out in :math:`(N, out_channels, T_{out}, V)`\n",
    "\n",
    "            where\n",
    "                :math:`N` is a batch size,\n",
    "                :math:`K` is the spatial kernel size, as :math:`K == kernel_size[1]`,\n",
    "                :math:`T_{in}/T_{out}` is a length of input/output sequence,\n",
    "                :math:`V` is the number of graph nodes.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 t_kernel_size=1,\n",
    "                 t_stride=1,\n",
    "                 t_padding=0,\n",
    "                 t_dilation=1,\n",
    "                 bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv = nn.Conv2d(in_channels,\n",
    "                              out_channels * kernel_size,\n",
    "                              kernel_size=(t_kernel_size, 1),\n",
    "                              padding=(t_padding, 0),\n",
    "                              stride=(t_stride, 1),\n",
    "                              dilation=(t_dilation, 1),\n",
    "                              bias=bias)\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        x = self.conv(x)\n",
    "        n, kc, t, v = x.size()\n",
    "        x = x.view(n, self.kernel_size, kc//self.kernel_size, t, v)\n",
    "        x = torch.einsum('nkctv,kvw->nctw', (x, A))\n",
    "\n",
    "        return x.contiguous()\n",
    "\n",
    "\n",
    "class st_gcn(nn.Module):\n",
    "    \"\"\"Applies a spatial temporal graph convolution over an input graph sequence.\n",
    "    Args:\n",
    "        - in_channels: (int) Number of channels in the input sequence data.\n",
    "        - out_channels: (int) Number of channels produced by the convolution.\n",
    "        - kernel_size: (tuple) Size of the temporal convolving kernel and\n",
    "            graph convolving kernel.\n",
    "        - stride: (int, optional) Stride of the temporal convolution. Default: 1\n",
    "        - dropout: (int, optional) Dropout rate of the final output. Default: 0\n",
    "        - residual: (bool, optional) If `True`, applies a residual mechanism.\n",
    "            Default: `True`\n",
    "    Shape:\n",
    "        - Inputs x: Graph sequence in :math: `(N, in_channels, T_{in}, V)`,\n",
    "                 A: Graph Adjecency matrix in :math: `(K, V, V)`,\n",
    "        - Output: Graph sequence out in :math: `(N, out_channels, T_{out}, V)`\n",
    "            where\n",
    "                :math:`N` is a batch size,\n",
    "                :math:`K` is the spatial kernel size, as :math:`K == kernel_size[1]`,\n",
    "                :math:`T_{in}/T_{out}` is a length of input/output sequence,\n",
    "                :math:`V` is the number of graph nodes.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 stride=1,\n",
    "                 dropout=0,\n",
    "                 residual=True):\n",
    "        super().__init__()\n",
    "        assert len(kernel_size) == 2\n",
    "        assert kernel_size[0] % 2 == 1\n",
    "        #print(kernel_size)(9, 3)\n",
    "        padding = ((kernel_size[0] - 1) // 2, 0)\n",
    "        #print(padding)(4, 0)\n",
    "\n",
    "        self.gcn = GraphConvolution(in_channels, out_channels, kernel_size[1])\n",
    "        self.tcn = nn.Sequential(nn.BatchNorm2d(out_channels),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                                 nn.Conv2d(out_channels,\n",
    "                                           out_channels,\n",
    "                                           (kernel_size[0], 1),\n",
    "                                           (stride, 1),\n",
    "                                           padding),\n",
    "                                 nn.BatchNorm2d(out_channels),\n",
    "                                 nn.Dropout(dropout, inplace=True),\n",
    "                                 )\n",
    "\n",
    "        if not residual:\n",
    "            self.residual = lambda x: 0\n",
    "        elif (in_channels == out_channels) and (stride == 1):\n",
    "            self.residual = lambda x: x\n",
    "        else:\n",
    "            self.residual = nn.Sequential(nn.Conv2d(in_channels,\n",
    "                                                    out_channels,\n",
    "                                                    kernel_size=1,\n",
    "                                                    stride=(stride, 1)),\n",
    "                                          nn.BatchNorm2d(out_channels)\n",
    "                                          )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        res = self.residual(x)\n",
    "        # print(res)\n",
    "        x = self.gcn(x, A)\n",
    "        #print(\"x_in:\",x.size())\n",
    "        x = self.tcn(x) + res\n",
    "        #print(\"x_out:\",x.size())\n",
    "        return self.relu(x)\n",
    "\n",
    "\n",
    "class StreamSpatialTemporalGraph(nn.Module):\n",
    "    \"\"\"Spatial temporal graph convolutional networks.\n",
    "    Args:\n",
    "        - in_channels: (int) Number of input channels.\n",
    "        - graph_args: (dict) Args map of `Actionsrecognition.Utils.Graph` Class.\n",
    "        - num_class: (int) Number of class outputs. If `None` return pooling features of\n",
    "            the last st-gcn layer instead.\n",
    "        - edge_importance_weighting: (bool) If `True`, adds a learnable importance\n",
    "            weighting to the edges of the graph.\n",
    "        - **kwargs: (optional) Other parameters for graph convolution units.\n",
    "    Shape:\n",
    "        - Input: :math:`(N, in_channels, T_{in}, V_{in})`\n",
    "        - Output: :math:`(N, num_class)` where\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`T_{in}` is a length of input sequence,\n",
    "            :math:`V_{in}` is the number of graph nodes,\n",
    "        or If num_class is `None`: `(N, out_channels)`\n",
    "            :math:`out_channels` is number of out_channels of the last layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, graph_args, num_class=None,\n",
    "                 edge_importance_weighting=True, **kwargs):\n",
    "        super().__init__()\n",
    "        # Load graph.\n",
    "        graph = Graph(**graph_args)\n",
    "        A = torch.tensor(graph.A, dtype=torch.float32, requires_grad=False)\n",
    "        self.register_buffer('A', A)\n",
    "\n",
    "        # Networks.\n",
    "        spatial_kernel_size = A.size(0)\n",
    "        temporal_kernel_size = 9\n",
    "        kernel_size = (temporal_kernel_size, spatial_kernel_size)\n",
    "        kwargs0 = {k: v for k, v in kwargs.items() if k != 'dropout'}\n",
    "\n",
    "        self.data_bn = nn.BatchNorm1d(in_channels * A.size(1))\n",
    "        self.st_gcn_networks = nn.ModuleList((\n",
    "            st_gcn(in_channels, 64, kernel_size, 1, residual=False, **kwargs0),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 128, kernel_size, 2, **kwargs),\n",
    "            st_gcn(128, 128, kernel_size, 1, **kwargs),\n",
    "            st_gcn(128, 128, kernel_size, 1, **kwargs),\n",
    "            st_gcn(128, 256, kernel_size, 2, **kwargs),\n",
    "            st_gcn(256, 256, kernel_size, 1, **kwargs),\n",
    "            st_gcn(256, 256, kernel_size, 1, **kwargs)\n",
    "        ))\n",
    "\n",
    "        # initialize parameters for edge importance weighting.\n",
    "        if edge_importance_weighting:\n",
    "            self.edge_importance = nn.ParameterList([\n",
    "                nn.Parameter(torch.ones(A.size()))\n",
    "                for i in self.st_gcn_networks\n",
    "            ])\n",
    "        else:\n",
    "            self.edge_importance = [1] * len(self.st_gcn_networks)\n",
    "\n",
    "        if num_class is not None:\n",
    "            self.cls = nn.Conv2d(256, num_class, kernel_size=1)\n",
    "        else:\n",
    "            self.cls = lambda x: x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # data normalization.\n",
    "        N, C, T, V = x.size()\n",
    "        x = x.permute(0, 3, 1, 2).contiguous()  # (N, V, C, T)\n",
    "        x = x.view(N, V * C, T)\n",
    "        x = self.data_bn(x)\n",
    "        x = x.view(N, V, C, T)\n",
    "        x = x.permute(0, 2, 3, 1).contiguous()\n",
    "        x = x.view(N, C, T, V)\n",
    "\n",
    "        # forward.\n",
    "        for gcn, importance in zip(self.st_gcn_networks, self.edge_importance):\n",
    "            x = gcn(x, self.A * importance)\n",
    "\n",
    "        x = F.avg_pool2d(x, x.size()[2:])\n",
    "        x = self.cls(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class TwoStreamSpatialTemporalGraph(nn.Module):\n",
    "    \"\"\"Two inputs spatial temporal graph convolutional networks.\n",
    "    Args:\n",
    "        - graph_args: (dict) Args map of `Actionsrecognition.Utils.Graph` Class.\n",
    "        - num_class: (int) Number of class outputs.\n",
    "        - edge_importance_weighting: (bool) If `True`, adds a learnable importance\n",
    "            weighting to the edges of the graph.\n",
    "        - **kwargs: (optional) Other parameters for graph convolution units.\n",
    "    Shape:\n",
    "        - Input: :tuple of math:`((N, 3, T, V), (N, 2, T, V))`\n",
    "        for points and motions stream where.\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`in_channels` is data channels (3 is (x, y, score)), (2 is (mot_x, mot_y))\n",
    "            :math:`T` is a length of input sequence,\n",
    "            :math:`V` is the number of graph nodes,\n",
    "        - Output: :math:`(N, num_class)`\n",
    "    \"\"\"\n",
    "    def __init__(self, graph_args, num_class, edge_importance_weighting=True,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.pts_stream = StreamSpatialTemporalGraph(3, graph_args, None,\n",
    "                                                     edge_importance_weighting,\n",
    "                                                     **kwargs)\n",
    "        self.mot_stream = StreamSpatialTemporalGraph(3, graph_args, None,\n",
    "                                                     edge_importance_weighting,\n",
    "                                                     **kwargs)\n",
    "\n",
    "        self.fcn = nn.Linear(256 * 2, num_class)\n",
    "        # self.fcn = nn.Linear(256 , num_class)\n",
    "        \n",
    "        # self.atten1 = nn.Linear(256 * 2, 128)\n",
    "        # self.atten_bn = nn.BatchNorm1d(128)\n",
    "        # self.atten_relu= nn.ReLU(inplace=True)\n",
    "        # self.atten2 = nn.Linear(128,32)\n",
    "        # self.atten_relu2= nn.ReLU(inplace=True)\n",
    "        # self.atten3 = nn.Linear(32, 256 * 2)\n",
    "        # self.atten_act = nn.Sigmoid() \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        out1 = self.pts_stream(inputs[0])\n",
    "        out2 = self.mot_stream(inputs[1])\n",
    "        \n",
    "        #print(out1.size())torch.Size([32, 256])\n",
    "        #print(out2.size())torch.Size([32, 256])\n",
    "        concat = torch.cat([out1, out2], dim=-1)\n",
    "        \n",
    "        # attn = self.atten1(concat)\n",
    "        # attn = self.atten_bn(attn)\n",
    "        # attn = self.atten_relu(attn)\n",
    "        # attn = self.atten2(attn)\n",
    "        # attn = self.atten_relu2(attn)\n",
    "        # attn = self.atten3(attn)\n",
    "        # attn = self.atten_act(attn)\n",
    "        # concat = concat * attn\n",
    "        \n",
    "        \n",
    "        out = self.fcn(concat)\n",
    "        # out = self.fcn(out1)\n",
    "        \n",
    "        return out\n",
    "        # return torch.sigmoid(out)\n",
    "        #return F.softmax(out,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1eaed456-195d-45ff-a875-632d9fe1a81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device\n",
      "(17983, 3, 116, 47)\n",
      "(17983,)\n",
      "number of params: 6272388\n",
      "Epoch 0/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:43<00:00,  4.34it/s,  loss: 0.7064, accu: 0.7222]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.66it/s,  loss: 0.9989, accu: 0.5385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 1.1090, accu: 0.6188\n",
      " - Valid loss: 0.7139, accu: 0.7365\n",
      "Epoch 1/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.31it/s,  loss: 0.5889, accu: 0.8333]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.60it/s,  loss: 1.4659, accu: 0.6923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.3621, accu: 0.8714\n",
      " - Valid loss: 1.2937, accu: 0.6690\n",
      "Epoch 2/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.30it/s,  loss: 0.7709, accu: 0.8333]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.62it/s,  loss: 0.0841, accu: 0.9231]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.1945, accu: 0.9330\n",
      " - Valid loss: 0.2577, accu: 0.9028\n",
      "Epoch 3/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.30it/s,  loss: 0.1026, accu: 0.9444]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.60it/s,  loss: 0.0993, accu: 0.9231]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.1069, accu: 0.9645\n",
      " - Valid loss: 0.0718, accu: 0.9794\n",
      "Epoch 4/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.31it/s,  loss: 0.0146, accu: 1.0000]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.64it/s,  loss: 0.0113, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0819, accu: 0.9733\n",
      " - Valid loss: 0.0471, accu: 0.9798\n",
      "Epoch 5/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.31it/s,  loss: 0.0785, accu: 0.9444]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.63it/s,  loss: 0.0142, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0610, accu: 0.9802\n",
      " - Valid loss: 0.0794, accu: 0.9679\n",
      "Epoch 6/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.30it/s,  loss: 0.0069, accu: 1.0000]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.62it/s,  loss: 0.0010, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0526, accu: 0.9847\n",
      " - Valid loss: 0.0123, accu: 0.9970\n",
      "Epoch 7/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.30it/s,  loss: 0.0080, accu: 1.0000]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.62it/s,  loss: 0.0005, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0338, accu: 0.9888\n",
      " - Valid loss: 0.0046, accu: 0.9997\n",
      "Epoch 8/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.30it/s,  loss: 0.0084, accu: 1.0000]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.62it/s,  loss: 0.0011, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0329, accu: 0.9897\n",
      " - Valid loss: 0.0037, accu: 0.9997\n",
      "Epoch 9/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.30it/s,  loss: 0.4532, accu: 0.8333]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.62it/s,  loss: 1.3023, accu: 0.6923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0307, accu: 0.9905\n",
      " - Valid loss: 0.7841, accu: 0.8037\n",
      "Epoch 10/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.30it/s,  loss: 0.0025, accu: 1.0000]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.62it/s,  loss: 0.0028, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0290, accu: 0.9923\n",
      " - Valid loss: 0.0199, accu: 0.9934\n",
      "Epoch 11/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.30it/s,  loss: 0.0009, accu: 1.0000]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.63it/s,  loss: 0.0003, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0205, accu: 0.9929\n",
      " - Valid loss: 0.0133, accu: 0.9945\n",
      "Epoch 12/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.31it/s,  loss: 0.0279, accu: 1.0000]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.62it/s,  loss: 0.0021, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0218, accu: 0.9933\n",
      " - Valid loss: 0.0187, accu: 0.9950\n",
      "Epoch 13/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.31it/s,  loss: 0.0023, accu: 1.0000]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.63it/s,  loss: 0.0005, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0211, accu: 0.9938\n",
      " - Valid loss: 0.0017, accu: 1.0000\n",
      "Epoch 14/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.31it/s,  loss: 0.0008, accu: 1.0000]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.62it/s,  loss: 0.0089, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0167, accu: 0.9951\n",
      " - Valid loss: 0.3571, accu: 0.9533\n",
      "Epoch 15/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.31it/s,  loss: 0.0094, accu: 1.0000]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.63it/s,  loss: 0.0023, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0212, accu: 0.9942\n",
      " - Valid loss: 0.0097, accu: 0.9961\n",
      "Epoch 16/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.31it/s,  loss: 0.0034, accu: 1.0000]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.63it/s,  loss: 0.0006, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0147, accu: 0.9955\n",
      " - Valid loss: 0.0022, accu: 0.9994\n",
      "Epoch 17/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.31it/s,  loss: 0.0005, accu: 1.0000]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.61it/s,  loss: 0.0000, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0146, accu: 0.9962\n",
      " - Valid loss: 0.0017, accu: 1.0000\n",
      "Epoch 18/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.31it/s,  loss: 0.0009, accu: 1.0000]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.63it/s,  loss: 0.0010, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0182, accu: 0.9944\n",
      " - Valid loss: 0.0134, accu: 0.9942\n",
      "Epoch 19/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.30it/s,  loss: 0.0001, accu: 1.0000]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.62it/s,  loss: 0.0002, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0128, accu: 0.9964\n",
      " - Valid loss: 0.0039, accu: 0.9997\n",
      "Epoch 20/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.30it/s,  loss: 0.0045, accu: 1.0000]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.63it/s,  loss: 0.0001, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0085, accu: 0.9972\n",
      " - Valid loss: 0.0032, accu: 0.9986\n",
      "Epoch 21/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.31it/s,  loss: 0.0000, accu: 1.0000]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.63it/s,  loss: 0.0003, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0086, accu: 0.9972\n",
      " - Valid loss: 0.0005, accu: 1.0000\n",
      "Epoch 22/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.30it/s,  loss: 0.0045, accu: 1.0000]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.62it/s,  loss: 0.0000, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0115, accu: 0.9964\n",
      " - Valid loss: 0.0025, accu: 0.9994\n",
      "Epoch 23/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.30it/s,  loss: 0.0190, accu: 1.0000]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.62it/s,  loss: 0.0001, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0129, accu: 0.9967\n",
      " - Valid loss: 0.0062, accu: 0.9975\n",
      "Epoch 24/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.30it/s,  loss: 0.0002, accu: 1.0000]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.62it/s,  loss: 0.0002, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0134, accu: 0.9958\n",
      " - Valid loss: 0.0107, accu: 0.9967\n",
      "Epoch 25/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.31it/s,  loss: 0.0000, accu: 1.0000]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.63it/s,  loss: 0.0000, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0094, accu: 0.9968\n",
      " - Valid loss: 0.0002, accu: 1.0000\n",
      "Epoch 26/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.30it/s,  loss: 0.0004, accu: 1.0000]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.63it/s,  loss: 0.0002, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0119, accu: 0.9969\n",
      " - Valid loss: 0.0015, accu: 0.9997\n",
      "Epoch 27/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.31it/s,  loss: 0.0002, accu: 1.0000]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.63it/s,  loss: 0.0001, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0099, accu: 0.9972\n",
      " - Valid loss: 0.0026, accu: 0.9986\n",
      "Epoch 28/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.31it/s,  loss: 0.0014, accu: 1.0000]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.63it/s,  loss: 0.0000, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0057, accu: 0.9978\n",
      " - Valid loss: 0.0007, accu: 1.0000\n",
      "Epoch 29/29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 450/450 [01:44<00:00,  4.30it/s,  loss: 0.0235, accu: 1.0000]\n",
      "valid: 100%|██████████| 113/113 [00:08<00:00, 12.60it/s,  loss: 0.0007, accu: 1.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0065, accu: 0.9978\n",
      " - Valid loss: 0.0020, accu: 0.9989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from shutil import copyfile\n",
    "from tqdm import tqdm\n",
    "from torch.utils import data\n",
    "from torch.optim.adadelta import Adadelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#device = 'cuda'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"using\", device, \"device\")\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 32 #32\n",
    "\n",
    "def load_dataset(data_files, batch_size, split_size=0.2,used_key_points=None):#0.2\n",
    "    \"\"\"Load data files into torch DataLoader with/without spliting train-test.\n",
    "    \"\"\"\n",
    "    features, labels = [], []\n",
    "    for fil in data_files:\n",
    "        with open(fil, 'rb') as f:\n",
    "            fts, lbs = pickle.load(f)\n",
    "            features.append(fts)\n",
    "            labels.append(lbs)\n",
    "        del fts, lbs\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    \n",
    "    if used_key_points != None:\n",
    "        features = features[:,:,:,used_key_points]\n",
    "    print(features.shape)\n",
    "    print(labels.shape)\n",
    "\n",
    "    if split_size > 0:\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(features, labels, test_size=split_size,random_state=0,stratify=labels)\n",
    "        \n",
    "        train_set = data.TensorDataset(torch.tensor(x_train, dtype=torch.float32),torch.tensor(y_train, dtype=torch.int64))\n",
    "        valid_set = data.TensorDataset(torch.tensor(x_valid, dtype=torch.float32),torch.tensor(y_valid, dtype=torch.int64))\n",
    "        train_loader = data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "        valid_loader = data.DataLoader(valid_set, batch_size)\n",
    "    else:\n",
    "        train_set = data.TensorDataset(torch.tensor(features, dtype=torch.float32),torch.tensor(labels, dtype=torch.int64))\n",
    "        train_loader = data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "        valid_loader = None\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "def accuracy_batch(y_pred, y_true):\n",
    "    # print(y_pred.shape,y_true.shape)\n",
    "    # return (y_pred.argmax(1) == y_true.argmax(1)).mean()\n",
    "    return (y_pred.argmax(1) == y_true).mean()\n",
    "\n",
    "\n",
    "def set_training(model, mode=True):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = mode\n",
    "    model.train(mode)\n",
    "    return model\n",
    "\n",
    "save_folder = os.path.join(os.environ['HOME'],\"KSL_V2/Outputs\")\n",
    "os.makedirs(save_folder,exist_ok=True)\n",
    "used_key_points=[0,11,12,13,14]+[i for i in range(33,33+21)] + [i for i in range(54,54+21)] \n",
    "train_loader, valid_loader = load_dataset([os.path.join(os.environ['HOME'],\"KSL_V2/Datasets/KSL_116_dataset.pkl\")], 32,0.2,used_key_points) #batch_size = 32\n",
    "dataloader = {'train': train_loader, 'valid': valid_loader}\n",
    "num_class=20\n",
    "\n",
    "graph_args = {'layout':'mediapipe_KSL','strategy': 'spatial'}\n",
    "model = TwoStreamSpatialTemporalGraph(graph_args, num_class).to(device)\n",
    "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"number of params: {n_parameters}\")\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "losser = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "loss_list = {'train': [], 'valid': []}\n",
    "accu_list = {'train': [], 'valid': []}\n",
    "best_acc = -1\n",
    "for e in range(epochs):\n",
    "    print('Epoch {}/{}'.format(e, epochs - 1))\n",
    "    for phase in ['train', 'valid']:\n",
    "        if phase == 'train':\n",
    "            model = set_training(model, True)\n",
    "        else:\n",
    "            model = set_training(model, False)\n",
    "\n",
    "        run_loss = 0.0\n",
    "        run_accu = 0.0\n",
    "        with tqdm(dataloader[phase], desc=phase) as iterator:\n",
    "            for pts, lbs in iterator:\n",
    "                # Create motion input by distance of points (x, y) of the same node\n",
    "                # in two frames.\n",
    "                mot = pts[:, :, 1:, :] - pts[:, :, :-1, :]\n",
    "\n",
    "                mot = mot.to(device)\n",
    "                pts = pts.to(device)\n",
    "                lbs = lbs.to(device)\n",
    "                \n",
    "                # Forward.\n",
    "                out = model((pts, mot))\n",
    "                #print(lbs)\n",
    "\n",
    "                #print(out)\n",
    "                loss = losser(out, lbs)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    # Backward.\n",
    "                    model.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                run_loss += loss.item()\n",
    "                accu = accuracy_batch(out.detach().cpu().numpy(),\n",
    "                                      lbs.detach().cpu().numpy())\n",
    "                run_accu += accu\n",
    "\n",
    "                iterator.set_postfix_str(' loss: {:.4f}, accu: {:.4f}'.format(\n",
    "                    loss.item(), accu))\n",
    "                iterator.update()\n",
    "                #break\n",
    "        loss_list[phase].append(run_loss / len(iterator))\n",
    "        accu_list[phase].append(run_accu / len(iterator))\n",
    "        #print(accu_list)\n",
    "        #print(torch.max(accu_list))\n",
    "    if(best_acc < accu_list['valid'][-1]):\n",
    "        best_acc = accu_list['valid'][-1]\n",
    "        torch.save(model.state_dict(), os.path.join(save_folder, 'tsstg-model_best.pth'))\n",
    "        #break\n",
    "\n",
    "    print('Summary epoch:\\n - Train loss: {:.4f}, accu: {:.4f}\\n - Valid loss:'\n",
    "          ' {:.4f}, accu: {:.4f}'.format(loss_list['train'][-1], accu_list['train'][-1],\n",
    "                                         loss_list['valid'][-1], accu_list['valid'][-1]))\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da299f0-3900-4433-bee5-4ed3ba8db98f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39410b7e-e78b-45d7-ad00-0ef0d899bf30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a50db82-4eae-49a6-b038-4c659dfee70f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca80b0f-d4e7-4c7e-a2a9-2d987c61917a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f2d748-4648-48e8-b607-51b18aa28999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ecd7d8-2575-4c4f-b6c2-a6b0e2a9cb70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85101817-c09f-4182-b5ca-d21a9576d94a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ba6503-4e33-48d6-96e6-0e852e07f29e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be8efa-670a-487a-988f-9287339583d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c9711e9-121c-42c7-a402-3ca5cf0b3b54",
   "metadata": {
    "tags": []
   },
   "source": [
    "# KSL77 Dataset ImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c938def7-5561-4fd6-b378-574d511072eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reference from: https://github.com/yysijie/st-gcn/blob/master/net/utils/graph.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Graph:\n",
    "    \"\"\"The Graph to model the skeletons extracted by the Alpha-Pose.\n",
    "    Args:\n",
    "        - strategy: (string) must be one of the follow candidates\n",
    "            - uniform: Uniform Labeling,\n",
    "            - distance: Distance Partitioning,\n",
    "            - spatial: Spatial Configuration,\n",
    "        For more information, please refer to the section 'Partition Strategies'\n",
    "            in our paper (https://arxiv.org/abs/1801.07455).\n",
    "        - layout: (string) must be one of the follow candidates\n",
    "            - coco_cut: Is COCO format but cut 4 joints (L-R ears, L-R eyes) out.\n",
    "        - max_hop: (int) the maximal distance between two connected nodes.\n",
    "        - dilation: (int) controls the spacing between the kernel points.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 layout='coco_cut',\n",
    "                 strategy='uniform',\n",
    "                 max_hop=1,\n",
    "                 dilation=1):\n",
    "        self.max_hop = max_hop\n",
    "        self.dilation = dilation\n",
    "\n",
    "        self.get_edge(layout)\n",
    "        self.hop_dis = get_hop_distance(self.num_node, self.edge, max_hop)\n",
    "        self.get_adjacency(strategy)\n",
    "\n",
    "    def get_edge(self, layout):\n",
    "        if layout == 'coco_cut':\n",
    "            self.num_node = 14\n",
    "            self_link = [(i, i) for i in range(self.num_node)]\n",
    "            neighbor_link = [(6, 4), (4, 2), (2, 13), (13, 1), (5, 3), (3, 1), (12, 10),\n",
    "                             (10, 8), (8, 2), (11, 9), (9, 7), (7, 1), (13, 0)]\n",
    "            self.edge = self_link + neighbor_link\n",
    "            self.center = 13\n",
    "            \n",
    "        elif layout == 'mediapipe_KSL':\n",
    "            self.num_node = 47\n",
    "            self_link = [(i, i) for i in range(self.num_node)]\n",
    "            # used_key_points=\n",
    "            # [0,11,12,13,14]+[i for i in range(33,33+21)] + [i for i in range(54,54+21)] \n",
    "            neighbor_link = [(0,1),(0,2),(1,3),(2,4),(3,26),(4,5), # nose-arms-wrist\n",
    "                             \n",
    "                             (5,6),(6,7),(7,8),(8,9),\n",
    "                             (5,10),(10,11),(11,12),(12,13),\n",
    "                             (5,14),(14,15),(15,16),(16,17),\n",
    "                             (5,18),(18,19),(19,20),(20,21),\n",
    "                             (5,22),(22,23),(23,24),(24,25),\n",
    "                             \n",
    "                             (26,27),(27,28),(28,29),(29,30),\n",
    "                             (26,31),(31,32),(32,33),(33,34),\n",
    "                             (26,35),(35,36),(36,37),(37,38),\n",
    "                             (26,39),(39,40),(40,41),(41,42),\n",
    "                             (26,43),(43,44),(44,45),(45,46),\n",
    "                            ]\n",
    "            self.edge = self_link + neighbor_link\n",
    "            self.center = 0\n",
    "        else:\n",
    "            raise ValueError('This layout is not supported!')\n",
    "\n",
    "    def get_adjacency(self, strategy):\n",
    "        valid_hop = range(0, self.max_hop + 1, self.dilation)\n",
    "        adjacency = np.zeros((self.num_node, self.num_node))\n",
    "        for hop in valid_hop:\n",
    "            adjacency[self.hop_dis == hop] = 1\n",
    "        normalize_adjacency = normalize_digraph(adjacency)\n",
    "\n",
    "        if strategy == 'uniform':\n",
    "            A = np.zeros((1, self.num_node, self.num_node))\n",
    "            A[0] = normalize_adjacency\n",
    "            self.A = A\n",
    "        elif strategy == 'distance':\n",
    "            A = np.zeros((len(valid_hop), self.num_node, self.num_node))\n",
    "            for i, hop in enumerate(valid_hop):\n",
    "                A[i][self.hop_dis == hop] = normalize_adjacency[self.hop_dis ==\n",
    "                                                                hop]\n",
    "            self.A = A\n",
    "        elif strategy == 'spatial':\n",
    "            A = []\n",
    "            for hop in valid_hop:\n",
    "                a_root = np.zeros((self.num_node, self.num_node))\n",
    "                a_close = np.zeros((self.num_node, self.num_node))\n",
    "                a_further = np.zeros((self.num_node, self.num_node))\n",
    "                for i in range(self.num_node):\n",
    "                    for j in range(self.num_node):\n",
    "                        if self.hop_dis[j, i] == hop:\n",
    "                            if self.hop_dis[j, self.center] == self.hop_dis[i, self.center]:\n",
    "                                a_root[j, i] = normalize_adjacency[j, i]\n",
    "                            elif self.hop_dis[j, self.center] > self.hop_dis[i, self.center]:\n",
    "                                a_close[j, i] = normalize_adjacency[j, i]\n",
    "                            else:\n",
    "                                a_further[j, i] = normalize_adjacency[j, i]\n",
    "                if hop == 0:\n",
    "                    A.append(a_root)\n",
    "                else:\n",
    "                    A.append(a_root + a_close)\n",
    "                    A.append(a_further)\n",
    "            A = np.stack(A)\n",
    "            self.A = A\n",
    "            #self.A = np.swapaxes(np.swapaxes(A, 0, 1), 1, 2)\n",
    "        else:\n",
    "            raise ValueError(\"This strategy is not supported!\")\n",
    "\n",
    "\n",
    "def get_hop_distance(num_node, edge, max_hop=1):\n",
    "    A = np.zeros((num_node, num_node))\n",
    "    for i, j in edge:\n",
    "        A[j, i] = 1\n",
    "        A[i, j] = 1\n",
    "\n",
    "    # compute hop steps\n",
    "    hop_dis = np.zeros((num_node, num_node)) + np.inf\n",
    "    transfer_mat = [np.linalg.matrix_power(A, d) for d in range(max_hop + 1)]\n",
    "    arrive_mat = (np.stack(transfer_mat) > 0)\n",
    "    for d in range(max_hop, -1, -1):\n",
    "        hop_dis[arrive_mat[d]] = d\n",
    "    return hop_dis\n",
    "\n",
    "\n",
    "def normalize_digraph(A):\n",
    "    Dl = np.sum(A, 0)\n",
    "    num_node = A.shape[0]\n",
    "    Dn = np.zeros((num_node, num_node))\n",
    "    for i in range(num_node):\n",
    "        if Dl[i] > 0:\n",
    "            Dn[i, i] = Dl[i]**(-1)\n",
    "    AD = np.dot(A, Dn)\n",
    "    return AD\n",
    "\n",
    "\n",
    "def normalize_undigraph(A):\n",
    "    Dl = np.sum(A, 0)\n",
    "    num_node = A.shape[0]\n",
    "    Dn = np.zeros((num_node, num_node))\n",
    "    for i in range(num_node):\n",
    "        if Dl[i] > 0:\n",
    "            Dn[i, i] = Dl[i]**(-0.5)\n",
    "    DAD = np.dot(np.dot(Dn, A), Dn)\n",
    "    return DAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "312d43a1-d0c9-483e-88c1-22afee86398a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reference from: https://github.com/yysijie/st-gcn/tree/master/net\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# from Actionsrecognition.Utils import Graph\n",
    "\n",
    "\n",
    "class GraphConvolution(nn.Module):\n",
    "    \"\"\"The basic module for applying a graph convolution.\n",
    "    Args:\n",
    "        - in_channel: (int) Number of channels in the input sequence data.\n",
    "        - out_channels: (int) Number of channels produced by the convolution.\n",
    "        - kernel_size: (int) Size of the graph convolving kernel.\n",
    "        - t_kernel_size: (int) Size of the temporal convolving kernel.\n",
    "        - t_stride: (int, optional) Stride of the temporal convolution. Default: 1\n",
    "        - t_padding: (int, optional) Temporal zero-padding added to both sides of\n",
    "            the input. Default: 0\n",
    "        - t_dilation: (int, optional) Spacing between temporal kernel elements. Default: 1\n",
    "        - bias: (bool, optional) If `True`, adds a learnable bias to the output.\n",
    "            Default: `True`\n",
    "    Shape:\n",
    "        - Inputs x: Graph sequence in :math:`(N, in_channels, T_{in}, V)`,\n",
    "                 A: Graph adjacency matrix in :math:`(K, V, V)`,\n",
    "        - Output: Graph sequence out in :math:`(N, out_channels, T_{out}, V)`\n",
    "\n",
    "            where\n",
    "                :math:`N` is a batch size,\n",
    "                :math:`K` is the spatial kernel size, as :math:`K == kernel_size[1]`,\n",
    "                :math:`T_{in}/T_{out}` is a length of input/output sequence,\n",
    "                :math:`V` is the number of graph nodes.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 t_kernel_size=1,\n",
    "                 t_stride=1,\n",
    "                 t_padding=0,\n",
    "                 t_dilation=1,\n",
    "                 bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv = nn.Conv2d(in_channels,\n",
    "                              out_channels * kernel_size,\n",
    "                              kernel_size=(t_kernel_size, 1),\n",
    "                              padding=(t_padding, 0),\n",
    "                              stride=(t_stride, 1),\n",
    "                              dilation=(t_dilation, 1),\n",
    "                              bias=bias)\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        x = self.conv(x)\n",
    "        n, kc, t, v = x.size()\n",
    "        x = x.view(n, self.kernel_size, kc//self.kernel_size, t, v)\n",
    "        x = torch.einsum('nkctv,kvw->nctw', (x, A))\n",
    "\n",
    "        return x.contiguous()\n",
    "\n",
    "\n",
    "class st_gcn(nn.Module):\n",
    "    \"\"\"Applies a spatial temporal graph convolution over an input graph sequence.\n",
    "    Args:\n",
    "        - in_channels: (int) Number of channels in the input sequence data.\n",
    "        - out_channels: (int) Number of channels produced by the convolution.\n",
    "        - kernel_size: (tuple) Size of the temporal convolving kernel and\n",
    "            graph convolving kernel.\n",
    "        - stride: (int, optional) Stride of the temporal convolution. Default: 1\n",
    "        - dropout: (int, optional) Dropout rate of the final output. Default: 0\n",
    "        - residual: (bool, optional) If `True`, applies a residual mechanism.\n",
    "            Default: `True`\n",
    "    Shape:\n",
    "        - Inputs x: Graph sequence in :math: `(N, in_channels, T_{in}, V)`,\n",
    "                 A: Graph Adjecency matrix in :math: `(K, V, V)`,\n",
    "        - Output: Graph sequence out in :math: `(N, out_channels, T_{out}, V)`\n",
    "            where\n",
    "                :math:`N` is a batch size,\n",
    "                :math:`K` is the spatial kernel size, as :math:`K == kernel_size[1]`,\n",
    "                :math:`T_{in}/T_{out}` is a length of input/output sequence,\n",
    "                :math:`V` is the number of graph nodes.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 stride=1,\n",
    "                 dropout=0,\n",
    "                 residual=True):\n",
    "        super().__init__()\n",
    "        assert len(kernel_size) == 2\n",
    "        assert kernel_size[0] % 2 == 1\n",
    "        #print(kernel_size)(9, 3)\n",
    "        padding = ((kernel_size[0] - 1) // 2, 0)\n",
    "        #print(padding)(4, 0)\n",
    "\n",
    "        self.gcn = GraphConvolution(in_channels, out_channels, kernel_size[1])\n",
    "        self.tcn = nn.Sequential(nn.BatchNorm2d(out_channels),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                                 nn.Conv2d(out_channels,\n",
    "                                           out_channels,\n",
    "                                           (kernel_size[0], 1),\n",
    "                                           (stride, 1),\n",
    "                                           padding),\n",
    "                                 nn.BatchNorm2d(out_channels),\n",
    "                                 nn.Dropout(dropout, inplace=True),\n",
    "                                 )\n",
    "\n",
    "        if not residual:\n",
    "            self.residual = lambda x: 0\n",
    "        elif (in_channels == out_channels) and (stride == 1):\n",
    "            self.residual = lambda x: x\n",
    "        else:\n",
    "            self.residual = nn.Sequential(nn.Conv2d(in_channels,\n",
    "                                                    out_channels,\n",
    "                                                    kernel_size=1,\n",
    "                                                    stride=(stride, 1)),\n",
    "                                          nn.BatchNorm2d(out_channels)\n",
    "                                          )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        res = self.residual(x)\n",
    "        # print(res)\n",
    "        x = self.gcn(x, A)\n",
    "        #print(\"x_in:\",x.size())\n",
    "        x = self.tcn(x) + res\n",
    "        #print(\"x_out:\",x.size())\n",
    "        return self.relu(x)\n",
    "\n",
    "\n",
    "class StreamSpatialTemporalGraph(nn.Module):\n",
    "    \"\"\"Spatial temporal graph convolutional networks.\n",
    "    Args:\n",
    "        - in_channels: (int) Number of input channels.\n",
    "        - graph_args: (dict) Args map of `Actionsrecognition.Utils.Graph` Class.\n",
    "        - num_class: (int) Number of class outputs. If `None` return pooling features of\n",
    "            the last st-gcn layer instead.\n",
    "        - edge_importance_weighting: (bool) If `True`, adds a learnable importance\n",
    "            weighting to the edges of the graph.\n",
    "        - **kwargs: (optional) Other parameters for graph convolution units.\n",
    "    Shape:\n",
    "        - Input: :math:`(N, in_channels, T_{in}, V_{in})`\n",
    "        - Output: :math:`(N, num_class)` where\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`T_{in}` is a length of input sequence,\n",
    "            :math:`V_{in}` is the number of graph nodes,\n",
    "        or If num_class is `None`: `(N, out_channels)`\n",
    "            :math:`out_channels` is number of out_channels of the last layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, graph_args, num_class=None,\n",
    "                 edge_importance_weighting=True, **kwargs):\n",
    "        super().__init__()\n",
    "        # Load graph.\n",
    "        graph = Graph(**graph_args)\n",
    "        A = torch.tensor(graph.A, dtype=torch.float32, requires_grad=False)\n",
    "        self.register_buffer('A', A)\n",
    "\n",
    "        # Networks.\n",
    "        spatial_kernel_size = A.size(0)\n",
    "        temporal_kernel_size = 9\n",
    "        kernel_size = (temporal_kernel_size, spatial_kernel_size)\n",
    "        kwargs0 = {k: v for k, v in kwargs.items() if k != 'dropout'}\n",
    "\n",
    "        self.data_bn = nn.BatchNorm1d(in_channels * A.size(1))\n",
    "        self.st_gcn_networks = nn.ModuleList((\n",
    "            st_gcn(in_channels, 64, kernel_size, 1, residual=False, **kwargs0),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 128, kernel_size, 2, **kwargs),\n",
    "            st_gcn(128, 128, kernel_size, 1, **kwargs),\n",
    "            st_gcn(128, 128, kernel_size, 1, **kwargs),\n",
    "            st_gcn(128, 256, kernel_size, 2, **kwargs),\n",
    "            st_gcn(256, 256, kernel_size, 1, **kwargs),\n",
    "            st_gcn(256, 256, kernel_size, 1, **kwargs)\n",
    "        ))\n",
    "\n",
    "        # initialize parameters for edge importance weighting.\n",
    "        if edge_importance_weighting:\n",
    "            self.edge_importance = nn.ParameterList([\n",
    "                nn.Parameter(torch.ones(A.size()))\n",
    "                for i in self.st_gcn_networks\n",
    "            ])\n",
    "        else:\n",
    "            self.edge_importance = [1] * len(self.st_gcn_networks)\n",
    "\n",
    "        if num_class is not None:\n",
    "            self.cls = nn.Conv2d(256, num_class, kernel_size=1)\n",
    "        else:\n",
    "            self.cls = lambda x: x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # data normalization.\n",
    "        N, C, T, V = x.size()\n",
    "        x = x.permute(0, 3, 1, 2).contiguous()  # (N, V, C, T)\n",
    "        x = x.view(N, V * C, T)\n",
    "        x = self.data_bn(x)\n",
    "        x = x.view(N, V, C, T)\n",
    "        x = x.permute(0, 2, 3, 1).contiguous()\n",
    "        x = x.view(N, C, T, V)\n",
    "\n",
    "        # forward.\n",
    "        for gcn, importance in zip(self.st_gcn_networks, self.edge_importance):\n",
    "            x = gcn(x, self.A * importance)\n",
    "\n",
    "        x = F.avg_pool2d(x, x.size()[2:])\n",
    "        x = self.cls(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class TwoStreamSpatialTemporalGraph(nn.Module):\n",
    "    \"\"\"Two inputs spatial temporal graph convolutional networks.\n",
    "    Args:\n",
    "        - graph_args: (dict) Args map of `Actionsrecognition.Utils.Graph` Class.\n",
    "        - num_class: (int) Number of class outputs.\n",
    "        - edge_importance_weighting: (bool) If `True`, adds a learnable importance\n",
    "            weighting to the edges of the graph.\n",
    "        - **kwargs: (optional) Other parameters for graph convolution units.\n",
    "    Shape:\n",
    "        - Input: :tuple of math:`((N, 3, T, V), (N, 2, T, V))`\n",
    "        for points and motions stream where.\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`in_channels` is data channels (3 is (x, y, score)), (2 is (mot_x, mot_y))\n",
    "            :math:`T` is a length of input sequence,\n",
    "            :math:`V` is the number of graph nodes,\n",
    "        - Output: :math:`(N, num_class)`\n",
    "    \"\"\"\n",
    "    def __init__(self, graph_args, num_class, edge_importance_weighting=True,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.pts_stream = StreamSpatialTemporalGraph(3, graph_args, None,\n",
    "                                                     edge_importance_weighting,\n",
    "                                                     **kwargs)\n",
    "        self.mot_stream = StreamSpatialTemporalGraph(3, graph_args, None,\n",
    "                                                     edge_importance_weighting,\n",
    "                                                     **kwargs)\n",
    "\n",
    "        # self.fcn = nn.Linear(256 * 2, num_class)\n",
    "        self.fcn = nn.Linear(256 , num_class)\n",
    "        \n",
    "        # self.atten1 = nn.Linear(256 * 2, 128)\n",
    "        # self.atten_bn = nn.BatchNorm1d(128)\n",
    "        # self.atten_relu= nn.ReLU(inplace=True)\n",
    "        # self.atten2 = nn.Linear(128,32)\n",
    "        # self.atten_relu2= nn.ReLU(inplace=True)\n",
    "        # self.atten3 = nn.Linear(32, 256 * 2)\n",
    "        # self.atten_act = nn.Sigmoid() \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        out1 = self.pts_stream(inputs[0])\n",
    "        # out2 = self.mot_stream(inputs[1])\n",
    "        \n",
    "        #print(out1.size())torch.Size([32, 256])\n",
    "        #print(out2.size())torch.Size([32, 256])\n",
    "        # concat = torch.cat([out1, out2], dim=-1)\n",
    "        \n",
    "        # attn = self.atten1(concat)\n",
    "        # attn = self.atten_bn(attn)\n",
    "        # attn = self.atten_relu(attn)\n",
    "        # attn = self.atten2(attn)\n",
    "        # attn = self.atten_relu2(attn)\n",
    "        # attn = self.atten3(attn)\n",
    "        # attn = self.atten_act(attn)\n",
    "        # concat = concat * attn\n",
    "        \n",
    "        \n",
    "        # out = self.fcn(concat)\n",
    "        out = self.fcn(out1)\n",
    "        \n",
    "        return out\n",
    "        # return torch.sigmoid(out)\n",
    "        #return F.softmax(out,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64f86996-a2ef-47f1-846d-e1d72fbba673",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device\n",
      "(108373, 3, 1, 47)\n",
      "(108373,)\n",
      "number of params: 6281917\n",
      "Epoch 0/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:45<00:00, 59.85it/s,  loss: 3.3436, accu: 0.1000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 190.58it/s,  loss: 1.9834, accu: 0.3636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 2.9000, accu: 0.2425\n",
      " - Valid loss: 2.3800, accu: 0.3538\n",
      "Epoch 1/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:44<00:00, 60.55it/s,  loss: 2.3424, accu: 0.4000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 191.18it/s,  loss: 1.7863, accu: 0.4545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 2.1478, accu: 0.4137\n",
      " - Valid loss: 2.1252, accu: 0.4200\n",
      "Epoch 2/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:44<00:00, 60.41it/s,  loss: 1.4630, accu: 0.6000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 190.60it/s,  loss: 1.0020, accu: 0.7273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 1.7351, accu: 0.5220\n",
      " - Valid loss: 1.2949, accu: 0.6395\n",
      "Epoch 3/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:44<00:00, 60.48it/s,  loss: 2.7902, accu: 0.3000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 191.13it/s,  loss: 1.7586, accu: 0.6364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 1.4600, accu: 0.5906\n",
      " - Valid loss: 1.7154, accu: 0.5171\n",
      "Epoch 4/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:44<00:00, 60.43it/s,  loss: 1.5890, accu: 0.6000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 190.87it/s,  loss: 0.5235, accu: 0.9091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 1.2659, accu: 0.6448\n",
      " - Valid loss: 1.0196, accu: 0.7128\n",
      "Epoch 5/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:39<00:00, 69.30it/s,  loss: 2.1312, accu: 0.4000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.86it/s,  loss: 1.1388, accu: 0.4545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 1.1187, accu: 0.6824\n",
      " - Valid loss: 0.9741, accu: 0.7222\n",
      "Epoch 6/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.21it/s,  loss: 2.1703, accu: 0.4000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.12it/s,  loss: 0.5841, accu: 0.9091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 1.0088, accu: 0.7102\n",
      " - Valid loss: 0.8123, accu: 0.7717\n",
      "Epoch 7/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.43it/s,  loss: 1.6991, accu: 0.5000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.25it/s,  loss: 0.8531, accu: 0.6364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.9284, accu: 0.7311\n",
      " - Valid loss: 0.8148, accu: 0.7683\n",
      "Epoch 8/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.21it/s,  loss: 2.1276, accu: 0.4000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.99it/s,  loss: 1.7987, accu: 0.5455]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.8580, accu: 0.7510\n",
      " - Valid loss: 1.5735, accu: 0.5567\n",
      "Epoch 9/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.44it/s,  loss: 2.2445, accu: 0.3000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.94it/s,  loss: 0.3580, accu: 0.9091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.8041, accu: 0.7656\n",
      " - Valid loss: 0.6062, accu: 0.8249\n",
      "Epoch 10/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.29it/s,  loss: 2.9110, accu: 0.3000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.64it/s,  loss: 0.1680, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.7573, accu: 0.7775\n",
      " - Valid loss: 0.5245, accu: 0.8514\n",
      "Epoch 11/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.35it/s,  loss: 2.0520, accu: 0.5000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.81it/s,  loss: 0.2512, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.7124, accu: 0.7906\n",
      " - Valid loss: 0.4538, accu: 0.8684\n",
      "Epoch 12/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.24it/s,  loss: 1.6595, accu: 0.5000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.64it/s,  loss: 0.3964, accu: 0.8182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.6736, accu: 0.8001\n",
      " - Valid loss: 0.5239, accu: 0.8455\n",
      "Epoch 13/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.30it/s,  loss: 2.9323, accu: 0.3000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.92it/s,  loss: 0.1104, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.6421, accu: 0.8084\n",
      " - Valid loss: 0.4840, accu: 0.8540\n",
      "Epoch 14/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.40it/s,  loss: 0.7315, accu: 0.8000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.39it/s,  loss: 0.1618, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.6174, accu: 0.8154\n",
      " - Valid loss: 0.4472, accu: 0.8650\n",
      "Epoch 15/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.32it/s,  loss: 1.0400, accu: 0.8000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.54it/s,  loss: 0.1784, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.5910, accu: 0.8225\n",
      " - Valid loss: 0.3724, accu: 0.8952\n",
      "Epoch 16/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.38it/s,  loss: 1.4912, accu: 0.5000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.90it/s,  loss: 0.2300, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.5748, accu: 0.8264\n",
      " - Valid loss: 0.4622, accu: 0.8668\n",
      "Epoch 17/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.19it/s,  loss: 3.7467, accu: 0.3000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.85it/s,  loss: 0.5743, accu: 0.8182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.5471, accu: 0.8351\n",
      " - Valid loss: 0.8949, accu: 0.7669\n",
      "Epoch 18/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.34it/s,  loss: 1.9030, accu: 0.4000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.70it/s,  loss: 0.1788, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.5420, accu: 0.8367\n",
      " - Valid loss: 0.3246, accu: 0.9060\n",
      "Epoch 19/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.39it/s,  loss: 0.8519, accu: 0.7000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.35it/s,  loss: 0.3225, accu: 0.9091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.5223, accu: 0.8431\n",
      " - Valid loss: 0.3260, accu: 0.9021\n",
      "Epoch 20/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 69.99it/s,  loss: 0.7988, accu: 0.8000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.07it/s,  loss: 0.0800, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.5040, accu: 0.8476\n",
      " - Valid loss: 0.2866, accu: 0.9174\n",
      "Epoch 21/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.33it/s,  loss: 2.3350, accu: 0.4000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.84it/s,  loss: 0.7983, accu: 0.8182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4855, accu: 0.8525\n",
      " - Valid loss: 0.4936, accu: 0.8633\n",
      "Epoch 22/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.22it/s,  loss: 1.1049, accu: 0.8000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.58it/s,  loss: 0.1969, accu: 0.9091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4735, accu: 0.8556\n",
      " - Valid loss: 0.2625, accu: 0.9263\n",
      "Epoch 23/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.34it/s,  loss: 1.1536, accu: 0.7000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.34it/s,  loss: 0.0298, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4601, accu: 0.8596\n",
      " - Valid loss: 0.2695, accu: 0.9248\n",
      "Epoch 24/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.39it/s,  loss: 0.7743, accu: 0.8000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.92it/s,  loss: 0.2202, accu: 0.9091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4505, accu: 0.8627\n",
      " - Valid loss: 0.2568, accu: 0.9265\n",
      "Epoch 25/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.21it/s,  loss: 0.7510, accu: 0.8000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.16it/s,  loss: 0.0803, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4427, accu: 0.8645\n",
      " - Valid loss: 0.2734, accu: 0.9232\n",
      "Epoch 26/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.36it/s,  loss: 3.1884, accu: 0.4000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.41it/s,  loss: 0.0752, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4272, accu: 0.8698\n",
      " - Valid loss: 0.3349, accu: 0.9016\n",
      "Epoch 27/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.39it/s,  loss: 1.2010, accu: 0.7000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.08it/s,  loss: 0.0486, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4133, accu: 0.8724\n",
      " - Valid loss: 0.2342, accu: 0.9303\n",
      "Epoch 28/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.30it/s,  loss: 1.6026, accu: 0.6000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.45it/s,  loss: 0.0382, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4151, accu: 0.8712\n",
      " - Valid loss: 0.3425, accu: 0.8991\n",
      "Epoch 29/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.23it/s,  loss: 0.7012, accu: 0.7000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.16it/s,  loss: 0.0733, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4026, accu: 0.8753\n",
      " - Valid loss: 0.2276, accu: 0.9311\n",
      "Epoch 30/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.41it/s,  loss: 1.2063, accu: 0.6000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.44it/s,  loss: 1.3047, accu: 0.4545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.3926, accu: 0.8790\n",
      " - Valid loss: 0.8432, accu: 0.7623\n",
      "Epoch 31/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.23it/s,  loss: 0.2402, accu: 1.0000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.69it/s,  loss: 0.0476, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.3841, accu: 0.8814\n",
      " - Valid loss: 0.2020, accu: 0.9418\n",
      "Epoch 32/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.43it/s,  loss: 1.2749, accu: 0.6000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.35it/s,  loss: 0.2168, accu: 0.9091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.3793, accu: 0.8821\n",
      " - Valid loss: 0.2450, accu: 0.9287\n",
      "Epoch 33/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.12it/s,  loss: 1.3503, accu: 0.6000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.52it/s,  loss: 0.1809, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.3670, accu: 0.8872\n",
      " - Valid loss: 0.2647, accu: 0.9224\n",
      "Epoch 34/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.24it/s,  loss: 1.2089, accu: 0.4000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.30it/s,  loss: 2.3271, accu: 0.5455]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.3645, accu: 0.8866\n",
      " - Valid loss: 1.1108, accu: 0.6937\n",
      "Epoch 35/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.30it/s,  loss: 0.9826, accu: 0.6000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.51it/s,  loss: 0.2727, accu: 0.9091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.3553, accu: 0.8889\n",
      " - Valid loss: 0.2586, accu: 0.9254\n",
      "Epoch 36/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.30it/s,  loss: 1.0177, accu: 0.6000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.12it/s,  loss: 1.3918, accu: 0.6364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.3561, accu: 0.8894\n",
      " - Valid loss: 0.9010, accu: 0.7515\n",
      "Epoch 37/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.28it/s,  loss: 1.8463, accu: 0.4000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.78it/s,  loss: 0.0371, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.3478, accu: 0.8909\n",
      " - Valid loss: 0.2431, accu: 0.9287\n",
      "Epoch 38/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.21it/s,  loss: 1.7115, accu: 0.6000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.81it/s,  loss: 0.1288, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.3379, accu: 0.8951\n",
      " - Valid loss: 0.4628, accu: 0.8656\n",
      "Epoch 39/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.32it/s,  loss: 2.0152, accu: 0.5000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.03it/s,  loss: 0.4778, accu: 0.7273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.3417, accu: 0.8936\n",
      " - Valid loss: 0.2061, accu: 0.9430\n",
      "Epoch 40/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.21it/s,  loss: 2.1741, accu: 0.6000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.10it/s,  loss: 0.0385, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.3246, accu: 0.8988\n",
      " - Valid loss: 0.2119, accu: 0.9400\n",
      "Epoch 41/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.39it/s,  loss: 1.4460, accu: 0.6000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 221.84it/s,  loss: 0.0520, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.3257, accu: 0.8983\n",
      " - Valid loss: 0.2065, accu: 0.9407\n",
      "Epoch 42/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.17it/s,  loss: 1.8447, accu: 0.4000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.98it/s,  loss: 0.2447, accu: 0.9091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.3241, accu: 0.8985\n",
      " - Valid loss: 0.2019, accu: 0.9437\n",
      "Epoch 43/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.32it/s,  loss: 0.5214, accu: 0.7000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.86it/s,  loss: 0.2143, accu: 0.8182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.3167, accu: 0.8999\n",
      " - Valid loss: 0.1890, accu: 0.9476\n",
      "Epoch 44/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.16it/s,  loss: 1.5972, accu: 0.5000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.71it/s,  loss: 0.2188, accu: 0.9091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.3123, accu: 0.9014\n",
      " - Valid loss: 0.2051, accu: 0.9413\n",
      "Epoch 45/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.21it/s,  loss: 1.2700, accu: 0.5000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.22it/s,  loss: 0.0266, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.3118, accu: 0.9025\n",
      " - Valid loss: 0.1889, accu: 0.9487\n",
      "Epoch 46/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.37it/s,  loss: 1.6142, accu: 0.6000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.23it/s,  loss: 2.2872, accu: 0.3636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.3095, accu: 0.9022\n",
      " - Valid loss: 1.0975, accu: 0.7027\n",
      "Epoch 47/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.51it/s,  loss: 0.8793, accu: 0.6000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.12it/s,  loss: 0.0330, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.3029, accu: 0.9046\n",
      " - Valid loss: 0.1923, accu: 0.9484\n",
      "Epoch 48/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.44it/s,  loss: 1.6992, accu: 0.7000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.44it/s,  loss: 0.0422, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2986, accu: 0.9050\n",
      " - Valid loss: 0.2081, accu: 0.9421\n",
      "Epoch 49/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.50it/s,  loss: 0.0979, accu: 1.0000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.89it/s,  loss: 0.0374, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2905, accu: 0.9079\n",
      " - Valid loss: 0.1578, accu: 0.9561\n",
      "Epoch 50/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.15it/s,  loss: 0.4378, accu: 0.9000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.00it/s,  loss: 0.0418, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2863, accu: 0.9097\n",
      " - Valid loss: 0.1734, accu: 0.9529\n",
      "Epoch 51/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.23it/s,  loss: 1.9617, accu: 0.7000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.63it/s,  loss: 0.1471, accu: 0.9091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2797, accu: 0.9114\n",
      " - Valid loss: 0.2380, accu: 0.9325\n",
      "Epoch 52/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.39it/s,  loss: 1.9343, accu: 0.4000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.97it/s,  loss: 0.1366, accu: 0.9091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2833, accu: 0.9100\n",
      " - Valid loss: 0.2213, accu: 0.9361\n",
      "Epoch 53/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.54it/s,  loss: 1.3485, accu: 0.6000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.84it/s,  loss: 0.4431, accu: 0.8182]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2780, accu: 0.9124\n",
      " - Valid loss: 0.2505, accu: 0.9253\n",
      "Epoch 54/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.24it/s,  loss: 1.0994, accu: 0.7000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.61it/s,  loss: 1.1953, accu: 0.6364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2715, accu: 0.9148\n",
      " - Valid loss: 0.6913, accu: 0.8028\n",
      "Epoch 55/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.41it/s,  loss: 1.0753, accu: 0.7000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.36it/s,  loss: 0.0288, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2717, accu: 0.9135\n",
      " - Valid loss: 0.1633, accu: 0.9537\n",
      "Epoch 56/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.42it/s,  loss: 0.3575, accu: 0.8000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.76it/s,  loss: 2.7954, accu: 0.4545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2669, accu: 0.9160\n",
      " - Valid loss: 1.8306, accu: 0.5687\n",
      "Epoch 57/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.37it/s,  loss: 1.1318, accu: 0.7000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.90it/s,  loss: 1.8620, accu: 0.6364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2719, accu: 0.9144\n",
      " - Valid loss: 0.8630, accu: 0.7672\n",
      "Epoch 58/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.45it/s,  loss: 0.5297, accu: 0.7000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 224.13it/s,  loss: 0.0492, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2670, accu: 0.9150\n",
      " - Valid loss: 0.1769, accu: 0.9508\n",
      "Epoch 59/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.15it/s,  loss: 0.5690, accu: 0.9000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 224.43it/s,  loss: 0.1314, accu: 0.9091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2620, accu: 0.9173\n",
      " - Valid loss: 0.1673, accu: 0.9529\n",
      "Epoch 60/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.43it/s,  loss: 1.3025, accu: 0.6000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.88it/s,  loss: 0.0989, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2624, accu: 0.9173\n",
      " - Valid loss: 0.1632, accu: 0.9553\n",
      "Epoch 61/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.14it/s,  loss: 0.5111, accu: 0.9000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 221.47it/s,  loss: 0.0246, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2591, accu: 0.9184\n",
      " - Valid loss: 0.1579, accu: 0.9563\n",
      "Epoch 62/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.41it/s,  loss: 1.7214, accu: 0.7000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.55it/s,  loss: 0.0277, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2561, accu: 0.9188\n",
      " - Valid loss: 0.2039, accu: 0.9402\n",
      "Epoch 63/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.49it/s,  loss: 1.3985, accu: 0.7000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.61it/s,  loss: 0.2536, accu: 0.9091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2497, accu: 0.9213\n",
      " - Valid loss: 0.4665, accu: 0.8634\n",
      "Epoch 64/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.44it/s,  loss: 0.6861, accu: 0.8000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 224.26it/s,  loss: 0.0183, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2515, accu: 0.9201\n",
      " - Valid loss: 0.1735, accu: 0.9532\n",
      "Epoch 65/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.43it/s,  loss: 3.1724, accu: 0.3000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.70it/s,  loss: 1.6129, accu: 0.6364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2393, accu: 0.9237\n",
      " - Valid loss: 0.8831, accu: 0.7654\n",
      "Epoch 66/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.39it/s,  loss: 1.2788, accu: 0.5000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.08it/s,  loss: 1.4234, accu: 0.6364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2373, accu: 0.9243\n",
      " - Valid loss: 1.0058, accu: 0.7311\n",
      "Epoch 67/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.55it/s,  loss: 3.0218, accu: 0.5000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.30it/s,  loss: 0.1388, accu: 0.9091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2447, accu: 0.9232\n",
      " - Valid loss: 0.2308, accu: 0.9342\n",
      "Epoch 68/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.33it/s,  loss: 1.7773, accu: 0.6000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.66it/s,  loss: 0.0347, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2369, accu: 0.9255\n",
      " - Valid loss: 0.1742, accu: 0.9508\n",
      "Epoch 69/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.39it/s,  loss: 0.8529, accu: 0.8000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.77it/s,  loss: 0.0062, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2367, accu: 0.9252\n",
      " - Valid loss: 0.1618, accu: 0.9558\n",
      "Epoch 70/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.45it/s,  loss: 0.5748, accu: 0.8000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.24it/s,  loss: 0.0142, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2330, accu: 0.9261\n",
      " - Valid loss: 0.1571, accu: 0.9558\n",
      "Epoch 71/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.49it/s,  loss: 2.0335, accu: 0.6000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 221.91it/s,  loss: 0.0631, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2370, accu: 0.9253\n",
      " - Valid loss: 0.1644, accu: 0.9535\n",
      "Epoch 72/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.43it/s,  loss: 1.9293, accu: 0.8000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 224.41it/s,  loss: 0.0096, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2295, accu: 0.9270\n",
      " - Valid loss: 0.1604, accu: 0.9565\n",
      "Epoch 73/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.46it/s,  loss: 1.7938, accu: 0.5000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.57it/s,  loss: 0.0441, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2324, accu: 0.9259\n",
      " - Valid loss: 0.2783, accu: 0.9184\n",
      "Epoch 74/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.53it/s,  loss: 1.9306, accu: 0.5000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.75it/s,  loss: 0.0400, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2246, accu: 0.9276\n",
      " - Valid loss: 0.2106, accu: 0.9432\n",
      "Epoch 75/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.46it/s,  loss: 0.3817, accu: 0.9000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.78it/s,  loss: 0.0136, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2221, accu: 0.9288\n",
      " - Valid loss: 0.1497, accu: 0.9592\n",
      "Epoch 76/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.39it/s,  loss: 1.2420, accu: 0.7000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.46it/s,  loss: 0.0454, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2219, accu: 0.9301\n",
      " - Valid loss: 0.1825, accu: 0.9487\n",
      "Epoch 77/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.28it/s,  loss: 0.5465, accu: 0.7000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 224.22it/s,  loss: 0.0121, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2285, accu: 0.9268\n",
      " - Valid loss: 0.1529, accu: 0.9582\n",
      "Epoch 78/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.47it/s,  loss: 0.9699, accu: 0.6000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.27it/s,  loss: 0.0174, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2189, accu: 0.9304\n",
      " - Valid loss: 0.1516, accu: 0.9579\n",
      "Epoch 79/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.56it/s,  loss: 0.9718, accu: 0.7000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 224.18it/s,  loss: 2.0938, accu: 0.5455]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2189, accu: 0.9300\n",
      " - Valid loss: 1.3549, accu: 0.6628\n",
      "Epoch 80/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.56it/s,  loss: 1.0795, accu: 0.6000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 224.07it/s,  loss: 0.0497, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2146, accu: 0.9312\n",
      " - Valid loss: 0.1584, accu: 0.9564\n",
      "Epoch 81/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.40it/s,  loss: 0.2472, accu: 0.9000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 224.06it/s,  loss: 2.3681, accu: 0.6364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2108, accu: 0.9324\n",
      " - Valid loss: 1.2893, accu: 0.6928\n",
      "Epoch 82/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.55it/s,  loss: 3.7780, accu: 0.3000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.73it/s,  loss: 3.4830, accu: 0.4545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2112, accu: 0.9324\n",
      " - Valid loss: 2.0759, accu: 0.5517\n",
      "Epoch 83/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.53it/s,  loss: 0.1936, accu: 0.9000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.44it/s,  loss: 0.1146, accu: 0.9091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2139, accu: 0.9311\n",
      " - Valid loss: 0.1364, accu: 0.9638\n",
      "Epoch 84/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.43it/s,  loss: 0.3663, accu: 0.9000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.22it/s,  loss: 0.0042, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2068, accu: 0.9336\n",
      " - Valid loss: 0.1427, accu: 0.9622\n",
      "Epoch 85/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.57it/s,  loss: 3.3459, accu: 0.3000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.47it/s,  loss: 0.1184, accu: 0.9091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2058, accu: 0.9340\n",
      " - Valid loss: 0.3111, accu: 0.9173\n",
      "Epoch 86/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.56it/s,  loss: 0.3515, accu: 1.0000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.64it/s,  loss: 0.1022, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2082, accu: 0.9334\n",
      " - Valid loss: 0.2278, accu: 0.9340\n",
      "Epoch 87/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.52it/s,  loss: 0.5623, accu: 0.7000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.73it/s,  loss: 0.1765, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2042, accu: 0.9341\n",
      " - Valid loss: 0.3018, accu: 0.9122\n",
      "Epoch 88/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.46it/s,  loss: 0.6045, accu: 0.8000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.52it/s,  loss: 0.0067, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.1985, accu: 0.9365\n",
      " - Valid loss: 0.1474, accu: 0.9609\n",
      "Epoch 89/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.36it/s,  loss: 0.0591, accu: 1.0000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.69it/s,  loss: 0.0678, accu: 0.9091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.1985, accu: 0.9361\n",
      " - Valid loss: 0.1420, accu: 0.9641\n",
      "Epoch 90/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.39it/s,  loss: 2.4193, accu: 0.2000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.46it/s,  loss: 0.0364, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2011, accu: 0.9351\n",
      " - Valid loss: 0.2279, accu: 0.9380\n",
      "Epoch 91/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.49it/s,  loss: 1.1122, accu: 0.7000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 224.06it/s,  loss: 0.0900, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2016, accu: 0.9352\n",
      " - Valid loss: 0.1820, accu: 0.9512\n",
      "Epoch 92/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.51it/s,  loss: 1.3285, accu: 0.6000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.56it/s,  loss: 0.0163, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.1945, accu: 0.9382\n",
      " - Valid loss: 0.1562, accu: 0.9569\n",
      "Epoch 93/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.44it/s,  loss: 1.4843, accu: 0.7000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.97it/s,  loss: 0.3289, accu: 0.9091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.1930, accu: 0.9383\n",
      " - Valid loss: 0.1361, accu: 0.9620\n",
      "Epoch 94/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.53it/s,  loss: 1.2258, accu: 0.7000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.33it/s,  loss: 1.1643, accu: 0.6364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.1870, accu: 0.9398\n",
      " - Valid loss: 0.7101, accu: 0.8072\n",
      "Epoch 95/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.55it/s,  loss: 1.3707, accu: 0.7000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 224.27it/s,  loss: 0.0261, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.1940, accu: 0.9372\n",
      " - Valid loss: 0.1654, accu: 0.9527\n",
      "Epoch 96/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.34it/s,  loss: 0.4672, accu: 0.8000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 224.63it/s,  loss: 1.1900, accu: 0.7273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.1956, accu: 0.9372\n",
      " - Valid loss: 0.5423, accu: 0.8561\n",
      "Epoch 97/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.52it/s,  loss: 1.0129, accu: 0.6000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 223.46it/s,  loss: 0.0555, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.1795, accu: 0.9420\n",
      " - Valid loss: 0.1534, accu: 0.9573\n",
      "Epoch 98/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.37it/s,  loss: 0.4786, accu: 0.8000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.60it/s,  loss: 0.0106, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.1914, accu: 0.9387\n",
      " - Valid loss: 0.1898, accu: 0.9502\n",
      "Epoch 99/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 2710/2710 [00:38<00:00, 70.49it/s,  loss: 1.3843, accu: 0.7000]\n",
      "valid: 100%|██████████| 678/678 [00:03<00:00, 222.87it/s,  loss: 0.8458, accu: 0.7273]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.1830, accu: 0.9406\n",
      " - Valid loss: 0.5291, accu: 0.8542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from shutil import copyfile\n",
    "from tqdm import tqdm\n",
    "from torch.utils import data\n",
    "from torch.optim.adadelta import Adadelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#device = 'cuda'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"using\", device, \"device\")\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 64 #32\n",
    "\n",
    "def load_dataset(data_files, batch_size, split_size=0.2,used_key_points=None):#0.2\n",
    "    \"\"\"Load data files into torch DataLoader with/without spliting train-test.\n",
    "    \"\"\"\n",
    "    features, labels = [], []\n",
    "    for fil in data_files:\n",
    "        with open(fil, 'rb') as f:\n",
    "            fts, lbs = pickle.load(f)\n",
    "            features.append(fts)\n",
    "            labels.append(lbs)\n",
    "        del fts, lbs\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    \n",
    "    if used_key_points != None:\n",
    "        features = features[:,:,:,used_key_points]\n",
    "    print(features.shape)\n",
    "    print(labels.shape)\n",
    "\n",
    "    if split_size > 0:\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(features, labels, test_size=split_size,random_state=0,stratify=labels)\n",
    "        \n",
    "        train_set = data.TensorDataset(torch.tensor(x_train, dtype=torch.float32),torch.tensor(y_train, dtype=torch.int64))\n",
    "        valid_set = data.TensorDataset(torch.tensor(x_valid, dtype=torch.float32),torch.tensor(y_valid, dtype=torch.int64))\n",
    "        train_loader = data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "        valid_loader = data.DataLoader(valid_set, batch_size)\n",
    "    else:\n",
    "        train_set = data.TensorDataset(torch.tensor(features, dtype=torch.float32),torch.tensor(labels, dtype=torch.int64))\n",
    "        train_loader = data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "        valid_loader = None\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "def accuracy_batch(y_pred, y_true):\n",
    "    # print(y_pred.shape,y_true.shape)\n",
    "    # return (y_pred.argmax(1) == y_true.argmax(1)).mean()\n",
    "    return (y_pred.argmax(1) == y_true).mean()\n",
    "\n",
    "\n",
    "def set_training(model, mode=True):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = mode\n",
    "    model.train(mode)\n",
    "    return model\n",
    "\n",
    "save_folder = os.path.join(os.environ['HOME'],\"KSL_V2/Outputs\")\n",
    "os.makedirs(save_folder,exist_ok=True)\n",
    "used_key_points=[0,11,12,13,14]+[i for i in range(33,33+21)] + [i for i in range(54,54+21)] \n",
    "train_loader, valid_loader = load_dataset([os.path.join(os.environ['HOME'],\"KSL_V2/Datasets/KSL77_1_dataset.pkl\")], 32,0.2,used_key_points) #batch_size = 32\n",
    "dataloader = {'train': train_loader, 'valid': valid_loader}\n",
    "num_class=77\n",
    "\n",
    "graph_args = {'layout':'mediapipe_KSL','strategy': 'spatial'}\n",
    "model = TwoStreamSpatialTemporalGraph(graph_args, num_class).to(device)\n",
    "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"number of params: {n_parameters}\")\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.0001)\n",
    "losser = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "loss_list = {'train': [], 'valid': []}\n",
    "accu_list = {'train': [], 'valid': []}\n",
    "best_acc = -1\n",
    "for e in range(epochs):\n",
    "    print('Epoch {}/{}'.format(e, epochs - 1))\n",
    "    for phase in ['train', 'valid']:\n",
    "        if phase == 'train':\n",
    "            model = set_training(model, True)\n",
    "        else:\n",
    "            model = set_training(model, False)\n",
    "\n",
    "        run_loss = 0.0\n",
    "        run_accu = 0.0\n",
    "        with tqdm(dataloader[phase], desc=phase) as iterator:\n",
    "            for pts, lbs in iterator:\n",
    "                # Create motion input by distance of points (x, y) of the same node\n",
    "                # in two frames.\n",
    "                mot = pts[:, :, 1:, :] - pts[:, :, :-1, :]\n",
    "\n",
    "                mot = mot.to(device)\n",
    "                pts = pts.to(device)\n",
    "                lbs = lbs.to(device)\n",
    "                \n",
    "                # Forward.\n",
    "                out = model((pts, mot))\n",
    "                #print(lbs)\n",
    "\n",
    "                #print(out)\n",
    "                loss = losser(out, lbs)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    # Backward.\n",
    "                    model.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                run_loss += loss.item()\n",
    "                accu = accuracy_batch(out.detach().cpu().numpy(),\n",
    "                                      lbs.detach().cpu().numpy())\n",
    "                run_accu += accu\n",
    "\n",
    "                iterator.set_postfix_str(' loss: {:.4f}, accu: {:.4f}'.format(\n",
    "                    loss.item(), accu))\n",
    "                iterator.update()\n",
    "                #break\n",
    "        loss_list[phase].append(run_loss / len(iterator))\n",
    "        accu_list[phase].append(run_accu / len(iterator))\n",
    "        #print(accu_list)\n",
    "        #print(torch.max(accu_list))\n",
    "    if(best_acc < accu_list['valid'][-1]):\n",
    "        best_acc = accu_list['valid'][-1]\n",
    "        torch.save(model.state_dict(), os.path.join(save_folder, 'tsstg-model_best.pth'))\n",
    "        #break\n",
    "\n",
    "    print('Summary epoch:\\n - Train loss: {:.4f}, accu: {:.4f}\\n - Valid loss:'\n",
    "          ' {:.4f}, accu: {:.4f}'.format(loss_list['train'][-1], accu_list['train'][-1],\n",
    "                                         loss_list['valid'][-1], accu_list['valid'][-1]))\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c8230d-ca5a-4ff1-8fbf-b91ac18e3c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1479b4-ed68-4483-9d1f-d50b4b110a86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2586b028-de34-4aa3-bc0a-117d375da99f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014aefec-c5a6-423f-83e7-c1f1fa916067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db724afb-e2c8-4220-9144-9a9101e755f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74550716-e776-4a12-9bb0-59f86b361a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e27ddd-3243-41c0-9412-1584dffa15b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a09d4f7-7581-4315-ad4f-c38c1e3f884b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955b1e56-ad31-4cc3-a5f5-13b17125d222",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25f5198-e240-4d15-8438-cc7c069cc86e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44281c92-605c-4aee-b15d-04cdf49c1380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f99249d-8c13-4a20-a660-6d5e06083a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "127c689c-8f9c-474d-b8d1-604844319d28",
   "metadata": {
    "tags": []
   },
   "source": [
    "# KSL77 Dataset Video Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc7ce18c-8d14-4781-b6e0-0dedb0f5e8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reference from: https://github.com/yysijie/st-gcn/blob/master/net/utils/graph.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Graph:\n",
    "    \"\"\"The Graph to model the skeletons extracted by the Alpha-Pose.\n",
    "    Args:\n",
    "        - strategy: (string) must be one of the follow candidates\n",
    "            - uniform: Uniform Labeling,\n",
    "            - distance: Distance Partitioning,\n",
    "            - spatial: Spatial Configuration,\n",
    "        For more information, please refer to the section 'Partition Strategies'\n",
    "            in our paper (https://arxiv.org/abs/1801.07455).\n",
    "        - layout: (string) must be one of the follow candidates\n",
    "            - coco_cut: Is COCO format but cut 4 joints (L-R ears, L-R eyes) out.\n",
    "        - max_hop: (int) the maximal distance between two connected nodes.\n",
    "        - dilation: (int) controls the spacing between the kernel points.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 layout='coco_cut',\n",
    "                 strategy='uniform',\n",
    "                 max_hop=1,\n",
    "                 dilation=1):\n",
    "        self.max_hop = max_hop\n",
    "        self.dilation = dilation\n",
    "\n",
    "        self.get_edge(layout)\n",
    "        self.hop_dis = get_hop_distance(self.num_node, self.edge, max_hop)\n",
    "        self.get_adjacency(strategy)\n",
    "\n",
    "    def get_edge(self, layout):\n",
    "        if layout == 'coco_cut':\n",
    "            self.num_node = 14\n",
    "            self_link = [(i, i) for i in range(self.num_node)]\n",
    "            neighbor_link = [(6, 4), (4, 2), (2, 13), (13, 1), (5, 3), (3, 1), (12, 10),\n",
    "                             (10, 8), (8, 2), (11, 9), (9, 7), (7, 1), (13, 0)]\n",
    "            self.edge = self_link + neighbor_link\n",
    "            self.center = 13\n",
    "            \n",
    "        elif layout == 'mediapipe_KSL':\n",
    "            self.num_node = 47\n",
    "            self_link = [(i, i) for i in range(self.num_node)]\n",
    "            # used_key_points=\n",
    "            # [0,11,12,13,14]+[i for i in range(33,33+21)] + [i for i in range(54,54+21)] \n",
    "            neighbor_link = [(0,1),(0,2),(1,3),(2,4),(3,26),(4,5), # nose-arms-wrist\n",
    "                             \n",
    "                             (5,6),(6,7),(7,8),(8,9),\n",
    "                             (5,10),(10,11),(11,12),(12,13),\n",
    "                             (5,14),(14,15),(15,16),(16,17),\n",
    "                             (5,18),(18,19),(19,20),(20,21),\n",
    "                             (5,22),(22,23),(23,24),(24,25),\n",
    "                             \n",
    "                             (26,27),(27,28),(28,29),(29,30),\n",
    "                             (26,31),(31,32),(32,33),(33,34),\n",
    "                             (26,35),(35,36),(36,37),(37,38),\n",
    "                             (26,39),(39,40),(40,41),(41,42),\n",
    "                             (26,43),(43,44),(44,45),(45,46),\n",
    "                            ]\n",
    "            self.edge = self_link + neighbor_link\n",
    "            self.center = 0\n",
    "        else:\n",
    "            raise ValueError('This layout is not supported!')\n",
    "\n",
    "    def get_adjacency(self, strategy):\n",
    "        valid_hop = range(0, self.max_hop + 1, self.dilation)\n",
    "        adjacency = np.zeros((self.num_node, self.num_node))\n",
    "        for hop in valid_hop:\n",
    "            adjacency[self.hop_dis == hop] = 1\n",
    "        normalize_adjacency = normalize_digraph(adjacency)\n",
    "\n",
    "        if strategy == 'uniform':\n",
    "            A = np.zeros((1, self.num_node, self.num_node))\n",
    "            A[0] = normalize_adjacency\n",
    "            self.A = A\n",
    "        elif strategy == 'distance':\n",
    "            A = np.zeros((len(valid_hop), self.num_node, self.num_node))\n",
    "            for i, hop in enumerate(valid_hop):\n",
    "                A[i][self.hop_dis == hop] = normalize_adjacency[self.hop_dis ==\n",
    "                                                                hop]\n",
    "            self.A = A\n",
    "        elif strategy == 'spatial':\n",
    "            A = []\n",
    "            for hop in valid_hop:\n",
    "                a_root = np.zeros((self.num_node, self.num_node))\n",
    "                a_close = np.zeros((self.num_node, self.num_node))\n",
    "                a_further = np.zeros((self.num_node, self.num_node))\n",
    "                for i in range(self.num_node):\n",
    "                    for j in range(self.num_node):\n",
    "                        if self.hop_dis[j, i] == hop:\n",
    "                            if self.hop_dis[j, self.center] == self.hop_dis[i, self.center]:\n",
    "                                a_root[j, i] = normalize_adjacency[j, i]\n",
    "                            elif self.hop_dis[j, self.center] > self.hop_dis[i, self.center]:\n",
    "                                a_close[j, i] = normalize_adjacency[j, i]\n",
    "                            else:\n",
    "                                a_further[j, i] = normalize_adjacency[j, i]\n",
    "                if hop == 0:\n",
    "                    A.append(a_root)\n",
    "                else:\n",
    "                    A.append(a_root + a_close)\n",
    "                    A.append(a_further)\n",
    "            A = np.stack(A)\n",
    "            self.A = A\n",
    "            #self.A = np.swapaxes(np.swapaxes(A, 0, 1), 1, 2)\n",
    "        else:\n",
    "            raise ValueError(\"This strategy is not supported!\")\n",
    "\n",
    "\n",
    "def get_hop_distance(num_node, edge, max_hop=1):\n",
    "    A = np.zeros((num_node, num_node))\n",
    "    for i, j in edge:\n",
    "        A[j, i] = 1\n",
    "        A[i, j] = 1\n",
    "\n",
    "    # compute hop steps\n",
    "    hop_dis = np.zeros((num_node, num_node)) + np.inf\n",
    "    transfer_mat = [np.linalg.matrix_power(A, d) for d in range(max_hop + 1)]\n",
    "    arrive_mat = (np.stack(transfer_mat) > 0)\n",
    "    for d in range(max_hop, -1, -1):\n",
    "        hop_dis[arrive_mat[d]] = d\n",
    "    return hop_dis\n",
    "\n",
    "\n",
    "def normalize_digraph(A):\n",
    "    Dl = np.sum(A, 0)\n",
    "    num_node = A.shape[0]\n",
    "    Dn = np.zeros((num_node, num_node))\n",
    "    for i in range(num_node):\n",
    "        if Dl[i] > 0:\n",
    "            Dn[i, i] = Dl[i]**(-1)\n",
    "    AD = np.dot(A, Dn)\n",
    "    return AD\n",
    "\n",
    "\n",
    "def normalize_undigraph(A):\n",
    "    Dl = np.sum(A, 0)\n",
    "    num_node = A.shape[0]\n",
    "    Dn = np.zeros((num_node, num_node))\n",
    "    for i in range(num_node):\n",
    "        if Dl[i] > 0:\n",
    "            Dn[i, i] = Dl[i]**(-0.5)\n",
    "    DAD = np.dot(np.dot(Dn, A), Dn)\n",
    "    return DAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76e8beeb-0f85-47b3-93ce-3f18d329ee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reference from: https://github.com/yysijie/st-gcn/tree/master/net\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# from Actionsrecognition.Utils import Graph\n",
    "\n",
    "\n",
    "class GraphConvolution(nn.Module):\n",
    "    \"\"\"The basic module for applying a graph convolution.\n",
    "    Args:\n",
    "        - in_channel: (int) Number of channels in the input sequence data.\n",
    "        - out_channels: (int) Number of channels produced by the convolution.\n",
    "        - kernel_size: (int) Size of the graph convolving kernel.\n",
    "        - t_kernel_size: (int) Size of the temporal convolving kernel.\n",
    "        - t_stride: (int, optional) Stride of the temporal convolution. Default: 1\n",
    "        - t_padding: (int, optional) Temporal zero-padding added to both sides of\n",
    "            the input. Default: 0\n",
    "        - t_dilation: (int, optional) Spacing between temporal kernel elements. Default: 1\n",
    "        - bias: (bool, optional) If `True`, adds a learnable bias to the output.\n",
    "            Default: `True`\n",
    "    Shape:\n",
    "        - Inputs x: Graph sequence in :math:`(N, in_channels, T_{in}, V)`,\n",
    "                 A: Graph adjacency matrix in :math:`(K, V, V)`,\n",
    "        - Output: Graph sequence out in :math:`(N, out_channels, T_{out}, V)`\n",
    "\n",
    "            where\n",
    "                :math:`N` is a batch size,\n",
    "                :math:`K` is the spatial kernel size, as :math:`K == kernel_size[1]`,\n",
    "                :math:`T_{in}/T_{out}` is a length of input/output sequence,\n",
    "                :math:`V` is the number of graph nodes.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 t_kernel_size=1,\n",
    "                 t_stride=1,\n",
    "                 t_padding=0,\n",
    "                 t_dilation=1,\n",
    "                 bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv = nn.Conv2d(in_channels,\n",
    "                              out_channels * kernel_size,\n",
    "                              kernel_size=(t_kernel_size, 1),\n",
    "                              padding=(t_padding, 0),\n",
    "                              stride=(t_stride, 1),\n",
    "                              dilation=(t_dilation, 1),\n",
    "                              bias=bias)\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        x = self.conv(x)\n",
    "        n, kc, t, v = x.size()\n",
    "        x = x.view(n, self.kernel_size, kc//self.kernel_size, t, v)\n",
    "        x = torch.einsum('nkctv,kvw->nctw', (x, A))\n",
    "\n",
    "        return x.contiguous()\n",
    "\n",
    "\n",
    "class st_gcn(nn.Module):\n",
    "    \"\"\"Applies a spatial temporal graph convolution over an input graph sequence.\n",
    "    Args:\n",
    "        - in_channels: (int) Number of channels in the input sequence data.\n",
    "        - out_channels: (int) Number of channels produced by the convolution.\n",
    "        - kernel_size: (tuple) Size of the temporal convolving kernel and\n",
    "            graph convolving kernel.\n",
    "        - stride: (int, optional) Stride of the temporal convolution. Default: 1\n",
    "        - dropout: (int, optional) Dropout rate of the final output. Default: 0\n",
    "        - residual: (bool, optional) If `True`, applies a residual mechanism.\n",
    "            Default: `True`\n",
    "    Shape:\n",
    "        - Inputs x: Graph sequence in :math: `(N, in_channels, T_{in}, V)`,\n",
    "                 A: Graph Adjecency matrix in :math: `(K, V, V)`,\n",
    "        - Output: Graph sequence out in :math: `(N, out_channels, T_{out}, V)`\n",
    "            where\n",
    "                :math:`N` is a batch size,\n",
    "                :math:`K` is the spatial kernel size, as :math:`K == kernel_size[1]`,\n",
    "                :math:`T_{in}/T_{out}` is a length of input/output sequence,\n",
    "                :math:`V` is the number of graph nodes.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 stride=1,\n",
    "                 dropout=0,\n",
    "                 residual=True):\n",
    "        super().__init__()\n",
    "        assert len(kernel_size) == 2\n",
    "        assert kernel_size[0] % 2 == 1\n",
    "        #print(kernel_size)(9, 3)\n",
    "        padding = ((kernel_size[0] - 1) // 2, 0)\n",
    "        #print(padding)(4, 0)\n",
    "\n",
    "        self.gcn = GraphConvolution(in_channels, out_channels, kernel_size[1])\n",
    "        self.tcn = nn.Sequential(nn.BatchNorm2d(out_channels),\n",
    "                                 nn.ReLU(inplace=True),\n",
    "                                 nn.Conv2d(out_channels,\n",
    "                                           out_channels,\n",
    "                                           (kernel_size[0], 1),\n",
    "                                           (stride, 1),\n",
    "                                           padding),\n",
    "                                 nn.BatchNorm2d(out_channels),\n",
    "                                 nn.Dropout(dropout, inplace=True),\n",
    "                                 )\n",
    "\n",
    "        if not residual:\n",
    "            self.residual = lambda x: 0\n",
    "        elif (in_channels == out_channels) and (stride == 1):\n",
    "            self.residual = lambda x: x\n",
    "        else:\n",
    "            self.residual = nn.Sequential(nn.Conv2d(in_channels,\n",
    "                                                    out_channels,\n",
    "                                                    kernel_size=1,\n",
    "                                                    stride=(stride, 1)),\n",
    "                                          nn.BatchNorm2d(out_channels)\n",
    "                                          )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        res = self.residual(x)\n",
    "        # print(res)\n",
    "        x = self.gcn(x, A)\n",
    "        #print(\"x_in:\",x.size())\n",
    "        x = self.tcn(x) + res\n",
    "        #print(\"x_out:\",x.size())\n",
    "        return self.relu(x)\n",
    "\n",
    "\n",
    "class StreamSpatialTemporalGraph(nn.Module):\n",
    "    \"\"\"Spatial temporal graph convolutional networks.\n",
    "    Args:\n",
    "        - in_channels: (int) Number of input channels.\n",
    "        - graph_args: (dict) Args map of `Actionsrecognition.Utils.Graph` Class.\n",
    "        - num_class: (int) Number of class outputs. If `None` return pooling features of\n",
    "            the last st-gcn layer instead.\n",
    "        - edge_importance_weighting: (bool) If `True`, adds a learnable importance\n",
    "            weighting to the edges of the graph.\n",
    "        - **kwargs: (optional) Other parameters for graph convolution units.\n",
    "    Shape:\n",
    "        - Input: :math:`(N, in_channels, T_{in}, V_{in})`\n",
    "        - Output: :math:`(N, num_class)` where\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`T_{in}` is a length of input sequence,\n",
    "            :math:`V_{in}` is the number of graph nodes,\n",
    "        or If num_class is `None`: `(N, out_channels)`\n",
    "            :math:`out_channels` is number of out_channels of the last layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, graph_args, num_class=None,\n",
    "                 edge_importance_weighting=True, **kwargs):\n",
    "        super().__init__()\n",
    "        # Load graph.\n",
    "        graph = Graph(**graph_args)\n",
    "        A = torch.tensor(graph.A, dtype=torch.float32, requires_grad=False)\n",
    "        self.register_buffer('A', A)\n",
    "\n",
    "        # Networks.\n",
    "        spatial_kernel_size = A.size(0)\n",
    "        temporal_kernel_size = 9\n",
    "        kernel_size = (temporal_kernel_size, spatial_kernel_size)\n",
    "        kwargs0 = {k: v for k, v in kwargs.items() if k != 'dropout'}\n",
    "\n",
    "        self.data_bn = nn.BatchNorm1d(in_channels * A.size(1))\n",
    "        self.st_gcn_networks = nn.ModuleList((\n",
    "            st_gcn(in_channels, 64, kernel_size, 1, residual=False, **kwargs0),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 128, kernel_size, 2, **kwargs),\n",
    "            st_gcn(128, 128, kernel_size, 1, **kwargs),\n",
    "            st_gcn(128, 128, kernel_size, 1, **kwargs),\n",
    "            st_gcn(128, 256, kernel_size, 2, **kwargs),\n",
    "            st_gcn(256, 256, kernel_size, 1, **kwargs),\n",
    "            st_gcn(256, 256, kernel_size, 1, **kwargs)\n",
    "        ))\n",
    "\n",
    "        # initialize parameters for edge importance weighting.\n",
    "        if edge_importance_weighting:\n",
    "            self.edge_importance = nn.ParameterList([\n",
    "                nn.Parameter(torch.ones(A.size()))\n",
    "                for i in self.st_gcn_networks\n",
    "            ])\n",
    "        else:\n",
    "            self.edge_importance = [1] * len(self.st_gcn_networks)\n",
    "\n",
    "        if num_class is not None:\n",
    "            self.cls = nn.Conv2d(256, num_class, kernel_size=1)\n",
    "        else:\n",
    "            self.cls = lambda x: x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # data normalization.\n",
    "        N, C, T, V = x.size()\n",
    "        x = x.permute(0, 3, 1, 2).contiguous()  # (N, V, C, T)\n",
    "        x = x.view(N, V * C, T)\n",
    "        x = self.data_bn(x)\n",
    "        x = x.view(N, V, C, T)\n",
    "        x = x.permute(0, 2, 3, 1).contiguous()\n",
    "        x = x.view(N, C, T, V)\n",
    "\n",
    "        # forward.\n",
    "        for gcn, importance in zip(self.st_gcn_networks, self.edge_importance):\n",
    "            x = gcn(x, self.A * importance)\n",
    "\n",
    "        x = F.avg_pool2d(x, x.size()[2:])\n",
    "        x = self.cls(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class TwoStreamSpatialTemporalGraph(nn.Module):\n",
    "    \"\"\"Two inputs spatial temporal graph convolutional networks.\n",
    "    Args:\n",
    "        - graph_args: (dict) Args map of `Actionsrecognition.Utils.Graph` Class.\n",
    "        - num_class: (int) Number of class outputs.\n",
    "        - edge_importance_weighting: (bool) If `True`, adds a learnable importance\n",
    "            weighting to the edges of the graph.\n",
    "        - **kwargs: (optional) Other parameters for graph convolution units.\n",
    "    Shape:\n",
    "        - Input: :tuple of math:`((N, 3, T, V), (N, 2, T, V))`\n",
    "        for points and motions stream where.\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`in_channels` is data channels (3 is (x, y, score)), (2 is (mot_x, mot_y))\n",
    "            :math:`T` is a length of input sequence,\n",
    "            :math:`V` is the number of graph nodes,\n",
    "        - Output: :math:`(N, num_class)`\n",
    "    \"\"\"\n",
    "    def __init__(self, graph_args, num_class, edge_importance_weighting=True,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.pts_stream = StreamSpatialTemporalGraph(3, graph_args, None,\n",
    "                                                     edge_importance_weighting,\n",
    "                                                     **kwargs)\n",
    "        self.mot_stream = StreamSpatialTemporalGraph(3, graph_args, None,\n",
    "                                                     edge_importance_weighting,\n",
    "                                                     **kwargs)\n",
    "\n",
    "        self.fcn = nn.Linear(256 * 2, num_class)\n",
    "        # self.fcn = nn.Linear(256 , num_class)\n",
    "        \n",
    "        # self.atten1 = nn.Linear(256 * 2, 128)\n",
    "        # self.atten_bn = nn.BatchNorm1d(128)\n",
    "        # self.atten_relu= nn.ReLU(inplace=True)\n",
    "        # self.atten2 = nn.Linear(128,32)\n",
    "        # self.atten_relu2= nn.ReLU(inplace=True)\n",
    "        # self.atten3 = nn.Linear(32, 256 * 2)\n",
    "        # self.atten_act = nn.Sigmoid() \n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        out1 = self.pts_stream(inputs[0])\n",
    "        out2 = self.mot_stream(inputs[1])\n",
    "        \n",
    "        #print(out1.size())torch.Size([32, 256])\n",
    "        #print(out2.size())torch.Size([32, 256])\n",
    "        concat = torch.cat([out1, out2], dim=-1)\n",
    "        \n",
    "        # attn = self.atten1(concat)\n",
    "        # attn = self.atten_bn(attn)\n",
    "        # attn = self.atten_relu(attn)\n",
    "        # attn = self.atten2(attn)\n",
    "        # attn = self.atten_relu2(attn)\n",
    "        # attn = self.atten3(attn)\n",
    "        # attn = self.atten_act(attn)\n",
    "        # concat = concat * attn\n",
    "        \n",
    "        \n",
    "        out = self.fcn(concat)\n",
    "        # out = self.fcn(out1)\n",
    "        \n",
    "        return out\n",
    "        # return torch.sigmoid(out)\n",
    "        #return F.softmax(out,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9dddea2-6648-4372-823f-15bb18b1c80b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device\n",
      "(78877, 3, 25, 47)\n",
      "(78877,)\n",
      "number of params: 6301629\n",
      "Epoch 0/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [01:58<00:00, 16.65it/s,  loss: 2.4502, accu: 0.3793]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 53.01it/s,  loss: 2.2034, accu: 0.3750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 2.5456, accu: 0.2990\n",
      " - Valid loss: 1.8127, accu: 0.4618\n",
      "Epoch 1/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [01:59<00:00, 16.47it/s,  loss: 0.8237, accu: 0.6552]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.69it/s,  loss: 1.8028, accu: 0.4688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 1.3821, accu: 0.5894\n",
      " - Valid loss: 1.4313, accu: 0.5927\n",
      "Epoch 2/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.36it/s,  loss: 0.3319, accu: 0.9655]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.52it/s,  loss: 1.1674, accu: 0.7188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.8636, accu: 0.7388\n",
      " - Valid loss: 0.8292, accu: 0.7608\n",
      "Epoch 3/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.2140, accu: 0.9655]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.39it/s,  loss: 1.1643, accu: 0.6562]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.5746, accu: 0.8248\n",
      " - Valid loss: 0.8759, accu: 0.7551\n",
      "Epoch 4/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.2298, accu: 0.9655]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.51it/s,  loss: 0.5384, accu: 0.7812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4033, accu: 0.8756\n",
      " - Valid loss: 0.5541, accu: 0.8434\n",
      "Epoch 5/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.1006, accu: 0.9655]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.48it/s,  loss: 0.6275, accu: 0.8125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.3002, accu: 0.9058\n",
      " - Valid loss: 0.4210, accu: 0.8763\n",
      "Epoch 6/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.0828, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.44it/s,  loss: 0.5091, accu: 0.8438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.2348, accu: 0.9265\n",
      " - Valid loss: 0.4455, accu: 0.9192\n",
      "Epoch 7/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.0847, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.48it/s,  loss: 0.2559, accu: 0.9062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.1845, accu: 0.9423\n",
      " - Valid loss: 0.2466, accu: 0.9404\n",
      "Epoch 8/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.1163, accu: 0.9310]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.39it/s,  loss: 0.3857, accu: 0.8750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.1582, accu: 0.9494\n",
      " - Valid loss: 0.2570, accu: 0.9359\n",
      "Epoch 9/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.3732, accu: 0.9310]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.43it/s,  loss: 0.5921, accu: 0.7812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.1374, accu: 0.9564\n",
      " - Valid loss: 0.5739, accu: 0.8469\n",
      "Epoch 10/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.1633, accu: 0.9310]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.35it/s,  loss: 0.1233, accu: 0.9375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.1171, accu: 0.9621\n",
      " - Valid loss: 0.4863, accu: 0.9311\n",
      "Epoch 11/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.1967, accu: 0.9655]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.36it/s,  loss: 0.4472, accu: 0.8438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.1030, accu: 0.9673\n",
      " - Valid loss: 0.5918, accu: 0.8804\n",
      "Epoch 12/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.1015, accu: 0.9655]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.36it/s,  loss: 0.2081, accu: 0.9375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0939, accu: 0.9699\n",
      " - Valid loss: 0.2986, accu: 0.9110\n",
      "Epoch 13/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.0117, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.41it/s,  loss: 0.0722, accu: 0.9688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0867, accu: 0.9727\n",
      " - Valid loss: 0.2224, accu: 0.9601\n",
      "Epoch 14/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.1135, accu: 0.9655]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.42it/s,  loss: 0.2801, accu: 0.8750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0783, accu: 0.9756\n",
      " - Valid loss: 0.3887, accu: 0.9199\n",
      "Epoch 15/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.3661, accu: 0.8276]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.39it/s,  loss: 1.6508, accu: 0.6250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0695, accu: 0.9774\n",
      " - Valid loss: 1.1863, accu: 0.7529\n",
      "Epoch 16/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.0025, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.42it/s,  loss: 0.0339, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0654, accu: 0.9789\n",
      " - Valid loss: 0.1270, accu: 0.9627\n",
      "Epoch 17/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.0058, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.44it/s,  loss: 0.4816, accu: 0.8750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0622, accu: 0.9800\n",
      " - Valid loss: 0.1650, accu: 0.9733\n",
      "Epoch 18/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.1415, accu: 0.9655]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.39it/s,  loss: 0.1046, accu: 0.9688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0553, accu: 0.9827\n",
      " - Valid loss: 0.3468, accu: 0.9163\n",
      "Epoch 19/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.0015, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.42it/s,  loss: 0.2024, accu: 0.9375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0527, accu: 0.9837\n",
      " - Valid loss: 0.2259, accu: 0.9457\n",
      "Epoch 20/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.1771, accu: 0.9310]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.40it/s,  loss: 0.6000, accu: 0.8125]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0478, accu: 0.9851\n",
      " - Valid loss: 0.5094, accu: 0.8916\n",
      "Epoch 21/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.0515, accu: 0.9655]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.42it/s,  loss: 0.2656, accu: 0.9375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0463, accu: 0.9853\n",
      " - Valid loss: 0.5792, accu: 0.8983\n",
      "Epoch 22/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.0026, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.45it/s,  loss: 0.0950, accu: 0.9375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0440, accu: 0.9858\n",
      " - Valid loss: 0.1943, accu: 0.9504\n",
      "Epoch 23/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.0002, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.45it/s,  loss: 0.1045, accu: 0.9375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0431, accu: 0.9861\n",
      " - Valid loss: 0.1805, accu: 0.9631\n",
      "Epoch 24/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.0102, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.44it/s,  loss: 0.1201, accu: 0.9375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0382, accu: 0.9879\n",
      " - Valid loss: 0.2000, accu: 0.9499\n",
      "Epoch 25/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.0050, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.40it/s,  loss: 0.1862, accu: 0.9688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0394, accu: 0.9877\n",
      " - Valid loss: 0.1216, accu: 0.9643\n",
      "Epoch 26/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:01<00:00, 16.30it/s,  loss: 0.0005, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.39it/s,  loss: 0.8294, accu: 0.8750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0340, accu: 0.9892\n",
      " - Valid loss: 0.5182, accu: 0.8927\n",
      "Epoch 27/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.30it/s,  loss: 0.0011, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.41it/s,  loss: 0.1049, accu: 0.9688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0359, accu: 0.9884\n",
      " - Valid loss: 0.1330, accu: 0.9657\n",
      "Epoch 28/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.30it/s,  loss: 0.1305, accu: 0.9655]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.43it/s,  loss: 0.2261, accu: 0.9375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0328, accu: 0.9895\n",
      " - Valid loss: 0.4336, accu: 0.9019\n",
      "Epoch 29/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.0357, accu: 0.9655]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.44it/s,  loss: 0.0838, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0318, accu: 0.9896\n",
      " - Valid loss: 0.2206, accu: 0.9563\n",
      "Epoch 30/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.0038, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.46it/s,  loss: 0.2611, accu: 0.9062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0311, accu: 0.9907\n",
      " - Valid loss: 0.3100, accu: 0.9295\n",
      "Epoch 31/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.30it/s,  loss: 0.0265, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.40it/s,  loss: 0.0444, accu: 0.9688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0305, accu: 0.9904\n",
      " - Valid loss: 0.1178, accu: 0.9665\n",
      "Epoch 32/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.0007, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.43it/s,  loss: 0.0481, accu: 0.9688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0284, accu: 0.9909\n",
      " - Valid loss: 0.2998, accu: 0.9741\n",
      "Epoch 33/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.0003, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.39it/s,  loss: 0.0369, accu: 0.9688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0254, accu: 0.9921\n",
      " - Valid loss: 0.3839, accu: 0.9600\n",
      "Epoch 34/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.0053, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.48it/s,  loss: 0.0881, accu: 0.9688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0281, accu: 0.9914\n",
      " - Valid loss: 0.1969, accu: 0.9634\n",
      "Epoch 35/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.0007, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.52it/s,  loss: 0.0065, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0222, accu: 0.9926\n",
      " - Valid loss: 0.1163, accu: 0.9778\n",
      "Epoch 36/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.33it/s,  loss: 0.0010, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.45it/s,  loss: 0.2758, accu: 0.9062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0260, accu: 0.9918\n",
      " - Valid loss: 0.2712, accu: 0.9515\n",
      "Epoch 37/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   2%|▏         | 49/1972 [00:02<01:28, 21.82it/s,  loss: 0.0083, accu: 1.0000]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.0008, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.48it/s,  loss: 0.1930, accu: 0.9375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0221, accu: 0.9932\n",
      " - Valid loss: 0.2855, accu: 0.9331\n",
      "Epoch 42/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  23%|██▎       | 445/1972 [00:24<01:19, 19.32it/s,  loss: 0.0112, accu: 1.0000]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.1957, accu: 0.9655]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.47it/s,  loss: 0.0072, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0214, accu: 0.9934\n",
      " - Valid loss: 0.2186, accu: 0.9752\n",
      "Epoch 46/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.33it/s,  loss: 0.0069, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.52it/s,  loss: 0.0360, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0196, accu: 0.9939\n",
      " - Valid loss: 0.1523, accu: 0.9674\n",
      "Epoch 47/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   9%|▉         | 179/1972 [00:09<01:42, 17.48it/s,  loss: 0.0130, accu: 1.0000]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.0000, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.47it/s,  loss: 0.0800, accu: 0.9688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0180, accu: 0.9946\n",
      " - Valid loss: 0.1328, accu: 0.9871\n",
      "Epoch 51/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.0041, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.52it/s,  loss: 0.0111, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0174, accu: 0.9947\n",
      " - Valid loss: 0.1462, accu: 0.9739\n",
      "Epoch 52/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  22%|██▏       | 430/1972 [00:23<01:34, 16.34it/s,  loss: 0.0004, accu: 1.0000]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.0009, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.47it/s,  loss: 0.2474, accu: 0.9375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0187, accu: 0.9943\n",
      " - Valid loss: 0.2137, accu: 0.9576\n",
      "Epoch 54/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  86%|████████▌ | 1693/1972 [01:38<00:16, 17.12it/s,  loss: 0.0039, accu: 1.0000]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.0001, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.48it/s,  loss: 0.0037, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0149, accu: 0.9951\n",
      " - Valid loss: 0.1137, accu: 0.9859\n",
      "Epoch 56/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.0160, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.50it/s,  loss: 0.0483, accu: 0.9688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0157, accu: 0.9950\n",
      " - Valid loss: 0.1542, accu: 0.9797\n",
      "Epoch 57/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.0002, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.46it/s,  loss: 0.1499, accu: 0.9375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0160, accu: 0.9948\n",
      " - Valid loss: 0.1434, accu: 0.9770\n",
      "Epoch 58/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.0007, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.38it/s,  loss: 0.0013, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0147, accu: 0.9951\n",
      " - Valid loss: 0.1374, accu: 0.9898\n",
      "Epoch 59/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.30it/s,  loss: 0.1220, accu: 0.9655]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.40it/s,  loss: 0.0009, accu: 1.0000] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0151, accu: 0.9952\n",
      " - Valid loss: 0.7283, accu: 0.9914\n",
      "Epoch 60/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.30it/s,  loss: 0.0001, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.42it/s,  loss: 0.0009, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0157, accu: 0.9952\n",
      " - Valid loss: 0.2255, accu: 0.9893\n",
      "Epoch 61/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.30it/s,  loss: 0.0000, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.40it/s,  loss: 0.0638, accu: 0.9688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0133, accu: 0.9958\n",
      " - Valid loss: 0.0985, accu: 0.9888\n",
      "Epoch 62/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.30it/s,  loss: 0.0003, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.35it/s,  loss: 0.0039, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0146, accu: 0.9954\n",
      " - Valid loss: 0.2447, accu: 0.9897\n",
      "Epoch 63/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.2109, accu: 0.9655]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.46it/s,  loss: 0.2009, accu: 0.9375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0131, accu: 0.9960\n",
      " - Valid loss: 0.2590, accu: 0.9716\n",
      "Epoch 64/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.0039, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.44it/s,  loss: 0.0013, accu: 1.0000] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0137, accu: 0.9959\n",
      " - Valid loss: 0.6978, accu: 0.9959\n",
      "Epoch 65/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.0002, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.50it/s,  loss: 0.0724, accu: 0.9688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0139, accu: 0.9956\n",
      " - Valid loss: 0.1108, accu: 0.9814\n",
      "Epoch 66/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.0000, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.45it/s,  loss: 0.0192, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0126, accu: 0.9960\n",
      " - Valid loss: 0.2781, accu: 0.9947\n",
      "Epoch 67/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.0037, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.47it/s,  loss: 0.0002, accu: 1.0000] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0118, accu: 0.9963\n",
      " - Valid loss: 0.4088, accu: 0.9967\n",
      "Epoch 68/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.0000, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.44it/s,  loss: 0.0117, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0136, accu: 0.9958\n",
      " - Valid loss: 0.1328, accu: 0.9900\n",
      "Epoch 69/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.3555, accu: 0.9655]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.42it/s,  loss: 0.1229, accu: 0.9688] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0131, accu: 0.9958\n",
      " - Valid loss: 0.3951, accu: 0.9622\n",
      "Epoch 70/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.0002, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.43it/s,  loss: 0.0038, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0121, accu: 0.9962\n",
      " - Valid loss: 0.0984, accu: 0.9800\n",
      "Epoch 71/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.0005, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.40it/s,  loss: 0.0052, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0110, accu: 0.9967\n",
      " - Valid loss: 0.3035, accu: 0.9949\n",
      "Epoch 72/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.0004, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.44it/s,  loss: 0.0037, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0119, accu: 0.9963\n",
      " - Valid loss: 0.1888, accu: 0.9946\n",
      "Epoch 73/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.0005, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.39it/s,  loss: 0.0385, accu: 0.9688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0118, accu: 0.9962\n",
      " - Valid loss: 0.1542, accu: 0.9887\n",
      "Epoch 74/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.0080, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.47it/s,  loss: 0.2219, accu: 0.9375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0131, accu: 0.9963\n",
      " - Valid loss: 0.3607, accu: 0.9549\n",
      "Epoch 75/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.33it/s,  loss: 0.0006, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.48it/s,  loss: 0.0126, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0114, accu: 0.9964\n",
      " - Valid loss: 0.1660, accu: 0.9792\n",
      "Epoch 76/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.33it/s,  loss: 0.0004, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.51it/s,  loss: 0.0369, accu: 0.9688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0112, accu: 0.9967\n",
      " - Valid loss: 0.2361, accu: 0.9518\n",
      "Epoch 77/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.33it/s,  loss: 0.0002, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.46it/s,  loss: 0.3671, accu: 0.9062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0107, accu: 0.9964\n",
      " - Valid loss: 0.4435, accu: 0.9262\n",
      "Epoch 78/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.1455, accu: 0.9655]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.43it/s,  loss: 0.0320, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0124, accu: 0.9964\n",
      " - Valid loss: 0.0537, accu: 0.9852\n",
      "Epoch 79/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.33it/s,  loss: 0.0001, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.47it/s,  loss: 0.3385, accu: 0.9375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0109, accu: 0.9964\n",
      " - Valid loss: 0.1375, accu: 0.9864\n",
      "Epoch 80/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.33it/s,  loss: 0.0029, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.41it/s,  loss: 0.0096, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0104, accu: 0.9967\n",
      " - Valid loss: 0.1307, accu: 0.9960\n",
      "Epoch 81/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.0003, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.46it/s,  loss: 0.0147, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0099, accu: 0.9969\n",
      " - Valid loss: 0.2091, accu: 0.9965\n",
      "Epoch 82/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.0004, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.37it/s,  loss: 0.0345, accu: 0.9688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0098, accu: 0.9968\n",
      " - Valid loss: 0.0931, accu: 0.9898\n",
      "Epoch 83/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.0001, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.42it/s,  loss: 0.0290, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0105, accu: 0.9965\n",
      " - Valid loss: 0.1286, accu: 0.9676\n",
      "Epoch 84/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.0162, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.46it/s,  loss: 0.1912, accu: 0.9688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0088, accu: 0.9971\n",
      " - Valid loss: 0.1025, accu: 0.9746\n",
      "Epoch 85/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.0000, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.39it/s,  loss: 0.0011, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0104, accu: 0.9968\n",
      " - Valid loss: 0.0692, accu: 0.9933\n",
      "Epoch 86/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.0531, accu: 0.9655]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.46it/s,  loss: 0.0002, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0093, accu: 0.9971\n",
      " - Valid loss: 0.1105, accu: 0.9886\n",
      "Epoch 87/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.0001, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.39it/s,  loss: 0.0157, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0102, accu: 0.9968\n",
      " - Valid loss: 0.0814, accu: 0.9811\n",
      "Epoch 88/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.0003, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.46it/s,  loss: 0.0004, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0112, accu: 0.9963\n",
      " - Valid loss: 0.0951, accu: 0.9741\n",
      "Epoch 89/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.32it/s,  loss: 0.0000, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.45it/s,  loss: 0.3591, accu: 0.9375]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0101, accu: 0.9970\n",
      " - Valid loss: 0.2690, accu: 0.9451\n",
      "Epoch 90/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.0000, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.42it/s,  loss: 0.0223, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0084, accu: 0.9975\n",
      " - Valid loss: 0.1487, accu: 0.9663\n",
      "Epoch 91/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.30it/s,  loss: 0.0069, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.46it/s,  loss: 0.0138, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0098, accu: 0.9968\n",
      " - Valid loss: 0.1049, accu: 0.9760\n",
      "Epoch 92/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.30it/s,  loss: 0.0000, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.44it/s,  loss: 0.0109, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0103, accu: 0.9969\n",
      " - Valid loss: 0.0923, accu: 0.9793\n",
      "Epoch 93/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.30it/s,  loss: 0.0002, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.43it/s,  loss: 0.0091, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0092, accu: 0.9972\n",
      " - Valid loss: 0.1683, accu: 0.9643\n",
      "Epoch 94/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.30it/s,  loss: 0.0000, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.42it/s,  loss: 0.0011, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0100, accu: 0.9970\n",
      " - Valid loss: 0.1520, accu: 0.9815\n",
      "Epoch 95/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.30it/s,  loss: 0.0000, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.52it/s,  loss: 0.0101, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0088, accu: 0.9971\n",
      " - Valid loss: 0.1476, accu: 0.9831\n",
      "Epoch 96/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.31it/s,  loss: 0.0000, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.47it/s,  loss: 0.0126, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0080, accu: 0.9974\n",
      " - Valid loss: 0.0998, accu: 0.9783\n",
      "Epoch 97/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.30it/s,  loss: 0.0000, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.45it/s,  loss: 0.3191, accu: 0.9062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0087, accu: 0.9974\n",
      " - Valid loss: 0.3692, accu: 0.9261\n",
      "Epoch 98/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:01<00:00, 16.30it/s,  loss: 0.0000, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.39it/s,  loss: 0.0015, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0089, accu: 0.9972\n",
      " - Valid loss: 0.0924, accu: 0.9821\n",
      "Epoch 99/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 1972/1972 [02:00<00:00, 16.30it/s,  loss: 0.0062, accu: 1.0000]\n",
      "valid: 100%|██████████| 493/493 [00:09<00:00, 52.43it/s,  loss: 0.0023, accu: 1.0000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.0082, accu: 0.9974\n",
      " - Valid loss: 0.0690, accu: 0.9860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from shutil import copyfile\n",
    "from tqdm import tqdm\n",
    "from torch.utils import data\n",
    "from torch.optim.adadelta import Adadelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#device = 'cuda'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"using\", device, \"device\")\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 64 #32\n",
    "\n",
    "def load_dataset(data_files, batch_size, split_size=0.2,used_key_points=None):#0.2\n",
    "    \"\"\"Load data files into torch DataLoader with/without spliting train-test.\n",
    "    \"\"\"\n",
    "    features, labels = [], []\n",
    "    for fil in data_files:\n",
    "        with open(fil, 'rb') as f:\n",
    "            fts, lbs = pickle.load(f)\n",
    "            features.append(fts)\n",
    "            labels.append(lbs)\n",
    "        del fts, lbs\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    \n",
    "    if used_key_points != None:\n",
    "        features = features[:,:,:,used_key_points]\n",
    "    print(features.shape)\n",
    "    print(labels.shape)\n",
    "\n",
    "    if split_size > 0:\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(features, labels, test_size=split_size,random_state=0,stratify=labels)\n",
    "        \n",
    "        train_set = data.TensorDataset(torch.tensor(x_train, dtype=torch.float32),torch.tensor(y_train, dtype=torch.int64))\n",
    "        valid_set = data.TensorDataset(torch.tensor(x_valid, dtype=torch.float32),torch.tensor(y_valid, dtype=torch.int64))\n",
    "        train_loader = data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "        valid_loader = data.DataLoader(valid_set, batch_size)\n",
    "    else:\n",
    "        train_set = data.TensorDataset(torch.tensor(features, dtype=torch.float32),torch.tensor(labels, dtype=torch.int64))\n",
    "        train_loader = data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "        valid_loader = None\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "def accuracy_batch(y_pred, y_true):\n",
    "    # print(y_pred.shape,y_true.shape)\n",
    "    # return (y_pred.argmax(1) == y_true.argmax(1)).mean()\n",
    "    return (y_pred.argmax(1) == y_true).mean()\n",
    "\n",
    "\n",
    "def set_training(model, mode=True):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = mode\n",
    "    model.train(mode)\n",
    "    return model\n",
    "\n",
    "save_folder = os.path.join(os.environ['HOME'],\"KSL_V2/Outputs\")\n",
    "os.makedirs(save_folder,exist_ok=True)\n",
    "used_key_points=[0,11,12,13,14]+[i for i in range(33,33+21)] + [i for i in range(54,54+21)] \n",
    "train_loader, valid_loader = load_dataset([os.path.join(os.environ['HOME'],\"KSL_V2/Datasets/KSL77_25_dataset.pkl\")], 32,0.2,used_key_points) #batch_size = 32\n",
    "dataloader = {'train': train_loader, 'valid': valid_loader}\n",
    "num_class=77\n",
    "\n",
    "graph_args = {'layout':'mediapipe_KSL','strategy': 'spatial'}\n",
    "model = TwoStreamSpatialTemporalGraph(graph_args, num_class).to(device)\n",
    "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"number of params: {n_parameters}\")\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "losser = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "loss_list = {'train': [], 'valid': []}\n",
    "accu_list = {'train': [], 'valid': []}\n",
    "best_acc = -1\n",
    "for e in range(epochs):\n",
    "    print('Epoch {}/{}'.format(e, epochs - 1))\n",
    "    for phase in ['train', 'valid']:\n",
    "        if phase == 'train':\n",
    "            model = set_training(model, True)\n",
    "        else:\n",
    "            model = set_training(model, False)\n",
    "\n",
    "        run_loss = 0.0\n",
    "        run_accu = 0.0\n",
    "        with tqdm(dataloader[phase], desc=phase) as iterator:\n",
    "            for pts, lbs in iterator:\n",
    "                # Create motion input by distance of points (x, y) of the same node\n",
    "                # in two frames.\n",
    "                mot = pts[:, :, 1:, :] - pts[:, :, :-1, :]\n",
    "\n",
    "                mot = mot.to(device)\n",
    "                pts = pts.to(device)\n",
    "                lbs = lbs.to(device)\n",
    "                \n",
    "                # Forward.\n",
    "                out = model((pts, mot))\n",
    "                #print(lbs)\n",
    "\n",
    "                #print(out)\n",
    "                loss = losser(out, lbs)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    # Backward.\n",
    "                    model.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                run_loss += loss.item()\n",
    "                accu = accuracy_batch(out.detach().cpu().numpy(),\n",
    "                                      lbs.detach().cpu().numpy())\n",
    "                run_accu += accu\n",
    "\n",
    "                iterator.set_postfix_str(' loss: {:.4f}, accu: {:.4f}'.format(\n",
    "                    loss.item(), accu))\n",
    "                iterator.update()\n",
    "                #break\n",
    "        loss_list[phase].append(run_loss / len(iterator))\n",
    "        accu_list[phase].append(run_accu / len(iterator))\n",
    "        #print(accu_list)\n",
    "        #print(torch.max(accu_list))\n",
    "    if(best_acc < accu_list['valid'][-1]):\n",
    "        best_acc = accu_list['valid'][-1]\n",
    "        torch.save(model.state_dict(), os.path.join(save_folder, 'tsstg-model_best.pth'))\n",
    "        #break\n",
    "\n",
    "    print('Summary epoch:\\n - Train loss: {:.4f}, accu: {:.4f}\\n - Valid loss:'\n",
    "          ' {:.4f}, accu: {:.4f}'.format(loss_list['train'][-1], accu_list['train'][-1],\n",
    "                                         loss_list['valid'][-1], accu_list['valid'][-1]))\n",
    "del model\n",
    "#0.996577079107505"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7e6555-808c-4d08-bd89-3195f085e069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt110",
   "language": "python",
   "name": "pt110"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
